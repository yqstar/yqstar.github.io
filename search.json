[{"title":"Pytorch系列自学教程(1):数据加载之Dataset和DataLoader使用","url":"/2022/05/05/Pytorch%E7%B3%BB%E5%88%97%E8%87%AA%E5%AD%A6%E6%95%99%E7%A8%8B-1-%E6%95%B0%E6%8D%AE%E5%8A%A0%E8%BD%BD%E4%B9%8BDataset%E5%92%8CDataLoader%E4%BD%BF%E7%94%A8/","content":"深度学习模型，区别于其他的机器学习模型，一方面，模型训练所需的数据量通常是非常大的，是无法一次性加载到内存中；另一方面，模型训练多采用基于梯度下降的优化方法对模型的权重和偏置进行逐步调整的，不可能一次性地在模型中进行正向传播和反向传播。通常，我们需要进行数据加载和预处理处理，将其封装成适合迭代训练的形式，具体会对整个数据进行随机打乱，然后将原始数据处理成一个一个的Batch，然后送到模型中进行训练。\n深度学习模型流程中一般都是先解决数据加载问题，包括数据的输入问题和预处理问题，数据加载处理在深度学习链路中起着非常重要的基础作用。这篇文章将介绍Pytorch对自定义数据集进行封装的方法。\nDataset、Batch、Iteration和Epoch的关系在介绍如何使用Pytorch加载数据前，简单介绍下，Dataset，Batch，Iteration 和 Epoch 的区别和关系。\n\n\n\n\n名词\n解释                                             \n\n\n\n\n  Dataset\n待训练的全量数据集                                      \n\n\n   Batch\n待训练全量数据集的一小部分样本对模型进行一次反向传播参数更新，这一小部分样本称为“一个Batch” \n\n\n Iteration\n使用一个Batch数据对模型进行一次参数更新的过程，称之为“一次Iteration”             \n\n\n   Epoch\n待训练全量数据集对模型进行一次完整的参数更新，称之为“一个Epoch”               \n\n\n\n\n假设DatasetSize=10，BatchSize=3，那么每个Epoch会执行4个Iteration，对应四个Batch，每个BatchSize大小分别包括3，3，3和1个样本。\n\nPytoch数据处理：DataSet和DataLoaderPytorch提供了几个有用的工具：torch.utils.data.Dataset类和torch.utils.data.DataLoader类，用于数据读取和预处理。基本流程是先把原始数据转变成torch.utils.data.Dataset类，随后把得到的torch.utils.data.Dataset类当作一个参数传递给torch.utils.data.DataLoader类，得到一个数据加载器，这个数据加载器每次可以返回一个Batch的数据供模型训练使用。\ntorch.utils.data.Dataset类torch.utils.data.Dataset是代表这一数据的抽象类，你可以自己定义数据类，继承和重写这个抽象类，只需要定义init，len和getitem这三个魔法函数,其中：\n\n_init_()：用于初始化原始数据的路径和文件名等。\n_len_()：用于返回数据集中的样本总个数。\n_getitem_()：用于返回指定索引的样本所对应的输入变量与输出变量。\n\n# class CustomDataset(torch.utils.data.Dataset):#需要继承data.Dataset#     def __init__(self):#         # TODO#         # 1. Initialize file path or list of file names.#         pass#     def __getitem__(self, index):#         # TODO#         # 1. Read one data from file (e.g. using numpy.fromfile, PIL.Image.open).#         # 2. Preprocess the data (e.g. torchvision.Transform).#         # 3. Return a data pair (e.g. image and label).#         #这里需要注意的是，第一步：read one data，是一个data#         pass#     def __len__(self):#         # You should change 0 to the total size of your dataset.#         pass\n用原始数据构造出来的Dataset子类可以理解成一个静态数据池，这个数据池使得我们可以用索引得到某个样本数据，而想要该数据池流动起来，源源不断地输出Batch供给给模型训练，还需要下一个工具DataLoader类。所以我们把创建的Dataset子类当参数传入即将构建的DataLoader类才是使用Dataset子类最终目的。\ntorch.utils.data.DataLoader类DataLoader(object)可用参数：\n\ndataset(Dataset): 传入的数据集。\nbatch_size(int, optional): 每个batch有多少样本。\nshuffle(bool, optional): 在每个epoch开始时，对数据进行打乱排序。\nsampler(Sampler, optional): 自定义从数据集中取样本的策略，如果指定这个参数，那么shuffle必须为False。\nbatch_sampler(Sampler, optional): 与sampler类似，但是一次只返回一个batch的indices（索引），需要注意的是，一旦指定了这个参数，那么batch_size,shuffle,sampler,drop_last就不能再配置（互斥）。\nnum_workers (int, optional): 决定了有几个进程来处理data loading。0意味着所有的数据都会被load进主进程。（默认为0）\ncollate_fn (callable, optional): 将一个list的sample组成一个mini-batch的函数。\npin_memory (bool, optional)： 如果设置为True，那么data loader将会在返回它们之前，将tensors拷贝到CUDA中的固定内存中。\ndrop_last (bool, optional):如果设置为True：这个是对最后的未完成的batch来说的，比如batch_size设置为64，而一个epoch只有100个样本，那么训练时后面36个样本会被丢弃。 如果为False（默认），那么会继续正常执行，只是最后的batch_size会小一点。\ntimeout(numeric, optional):如果是正数，表明等待从worker进程中收集一个batch等待时间，若超出设定时间还没有收集到，那就不收集这个内容。这个numeric应总是大于等于0。默认为0\nworker_init_fn (callable, optional): 每个worker初始化函数。 \n\n实例txt数据读取使用个人创建的txt文件数据，进行数据读取操作。\nimport torchimport numpy as npfrom torch.utils.data import Dataset, DataLoaderclass SampleTxtDataset(Dataset):    def __init__(self):        # 数据文件地址        self.txt_file_path = &quot;./sample_easy_data.txt&quot;    def __getitem__(self, item):        txt_data = np.loadtxt(self.txt_file_path, delimiter=&quot;,&quot;)        self._x = torch.from_numpy(txt_data[:, :2])        self._y = torch.from_numpy(txt_data[:, 2])        return self._x[item], self._y[item]    def __len__(self):        txt_data = np.loadtxt(self.txt_file_path, delimiter=&quot;,&quot;)        self._len = len(txt_data)        return self._lensample_txt_dataset = SampleTxtDataset()print(&quot;Data Size:&quot;,len(sample_txt_dataset))print(&quot;First Sample:&quot;,next(iter(sample_txt_dataset)))print(&quot;First Sample&#x27;s Type:&quot;,type(next(iter(sample_txt_dataset))[0]))sample_dataloader = DataLoader(dataset=sample_txt_dataset, batch_size=3, shuffle=True)num_epochs = 4for epoch in range(num_epochs):    for iteration, (batch_x, batch_y) in enumerate(sample_dataloader):        print(&#x27;Epoch: &#x27;, epoch, &#x27;| Iteration: &#x27;, iteration, &#x27;| batch x: &#x27;, batch_x.numpy(), &#x27;| batch y: &#x27;, batch_y.numpy())\nDataset的示例结果：\n\nDataLoader的示例结果：\n\ncsv文件读取使用常见离线数据csv文件进行数据加载和预处理。\nimport torchimport pandas as pdfrom torch.utils.data import Dataset, DataLoaderclass SampleCsvDataset(Dataset):    def __init__(self):        self.csv_file_path = &quot;./sample_boston.csv&quot;    def __getitem__(self, item):        raw_data = pd.read_csv(self.csv_file_path)        raw_data_shape = raw_data.shape        self._x  = torch.from_numpy(raw_data.iloc[:,:raw_data_shape[1]-1].values)        self._y  = torch.from_numpy(raw_data.iloc[:,raw_data_shape[1]-1].values)        return self._x[item], self._y[item]    def __len__(self):        raw_data = pd.read_csv(self.csv_file_path)        raw_data_shape = raw_data.shape        self._len = raw_data_shape[0]        return self._lensample_csv_dataset = SampleCsvDataset()print(&quot;Data Size:&quot;,len(sample_csv_dataset))print(&quot;First Sample:&quot;,next(iter(sample_csv_dataset)))print(&quot;First Sample&#x27;s Type:&quot;,type(next(iter(sample_csv_dataset))[0]))sample_dataloader = DataLoader(dataset=sample_csv_dataset, batch_size=3, shuffle=True)num_epochs = 4for epoch in range(num_epochs):    for iteration, (batch_x, batch_y) in enumerate(sample_dataloader):        print(&#x27;Epoch: &#x27;, epoch, &#x27;| Iteration: &#x27;, iteration, &#x27;| batch x: &#x27;, batch_x.numpy(), &#x27;| batch y: &#x27;, batch_y.numpy())\nmysql数据读取生产落地数据多为数据库，本文也针对常见Mysql数据库进行了数据加载，使用的是MYSQL8.0数据库的示例数据库sakila.payment表进行数据读取演示。\nimport torchimport pandas as pdimport pymysqlfrom torch.utils.data import Dataset, DataLoaderclass SampleMysqlDataset(Dataset):    def __init__(self):        # 初始化MySQL数据库连接配置参数        self.mysql_host = &quot;localhost&quot;        self.mysql_port = 3307        self.mysql_user = &quot;utest&quot;        self.mysql_password = &quot;123456xyq&quot;        self.mysql_db = &quot;sakila&quot;        self.mysql_table = &quot;payment&quot;        self.mysql_charset = &quot;utf8&quot;        self.mysql_sql_data = &quot;select payment_id, customer_id, staff_id, rental_id, amount from sakila.payment&quot;        self.mysql_sql_cnt = &quot;select count(*) from sakila.payment&quot;    def __getitem__(self, item):        # 创建数据库连接        conn = pymysql.connect(host=self.mysql_host,                        port=self.mysql_port,                        user=self.mysql_user,                        password=self.mysql_password,                        db=self.mysql_db,                        charset=self.mysql_charset)        raw_dataframe = pd.read_sql(self.mysql_sql_data, conn)        raw_dataframe_shape = raw_dataframe.shape        self._x  = torch.from_numpy(raw_dataframe.iloc[:,:raw_dataframe_shape[1]-1].values)        self._y  = torch.from_numpy(raw_dataframe.iloc[:,raw_dataframe_shape[1]-1].values)        return self._x[item], self._y[item]    def __len__(self):        # 创建数据库连接        conn = pymysql.connect(host=self.mysql_host,                        port=self.mysql_port,                        user=self.mysql_user,                        password=self.mysql_password,                        db=self.mysql_db,                        charset=self.mysql_charset)        raw_dataframe = pd.read_sql(self.mysql_sql_data, conn)        raw_dataframe_shape = raw_dataframe.shape        self._len = raw_dataframe_shape[0]        return self._lensample_mysql_dataset = SampleMysqlDataset()print(&quot;Data Size:&quot;,len(sample_mysql_dataset))print(&quot;First Sample:&quot;,next(iter(sample_mysql_dataset)))print(&quot;First Sample&#x27;s Type:&quot;,type(next(iter(sample_mysql_dataset))[0]))sample_dataloader = DataLoader(dataset=sample_mysql_dataset, batch_size=3, shuffle=True)num_epochs = 4for epoch in range(num_epochs):    for iteration, (batch_x, batch_y) in enumerate(sample_dataloader):        print(&#x27;Epoch: &#x27;, epoch, &#x27;| Iteration: &#x27;, iteration, &#x27;| batch x: &#x27;, batch_x.numpy(), &#x27;| batch y: &#x27;, batch_y.numpy())\n使用pytorch自带数据集为方便快速试验，Pytorch也集成了常见的数据集在torchaudio，torchtext和torchvision中，本代码使用torchvision读取常用的图像算法数据集MNIST，具体代码如下。\nfrom torchvision import datasets, transformsfrom torch.utils.data import DataLoader# 导入训练集sample_mnist_dataset = datasets.MNIST(root=r&#x27;./data&#x27;,                              transform=transforms.ToTensor(),                              train=True,                              download=True)print(&quot;Data Size:&quot;,len(sample_mnist_dataset))print(&quot;First Sample:&quot;,next(iter(sample_mnist_dataset)))print(&quot;First Sample&#x27;s Type:&quot;,type(next(iter(sample_mnist_dataset))[0]))sample_dataloader = DataLoader(dataset=sample_mnist_dataset, batch_size=3, shuffle=True)num_epochs = 4for epoch in range(num_epochs):    for iter, (batch_x, batch_y) in enumerate(sample_dataloader):        print(&#x27;Epoch: &#x27;, epoch, &#x27;| Iteration: &#x27;, iter, &#x27;| batch x: &#x27;, batch_x.numpy(), &#x27;| batch y: &#x27;, batch_y.numpy())\n开放探索\n如何将完整数据集划分成训练集、测试集和验证集呢？\n\n生产读取大量数据无法一次加载到内存该如何操作呢？\n\n如何使用TorchData进行数据读取和预处理？\n\n\n参考More info: pan_jinquan：Dataset, DataLoader产生自定义的训练数据\nMore info: 夜和大帝：Dataset类的使用\nMore info: setail：pytorch_tutorial\nMore info: Ericam_：十分钟搞懂Pytorch如何读取MNIST数据集\nMore info: Chenllliang：两文读懂PyTorch中Dataset与DataLoader（一）打造自己的数据集\nMore Info: cici_iii：大数据量下如何使用Dataset和IterDataset构建数据集\nMore Info: csdn-WJW: 如何划分训练集，测试集和验证集\n","categories":["深度学习"],"tags":["Pytorch"]},{"title":"Windows系统使用Conda配置深度学习环境","url":"/2022/05/06/Windows%E7%B3%BB%E7%BB%9F%E4%BD%BF%E7%94%A8Conda%E9%85%8D%E7%BD%AE%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83/","content":"Conda环境管理Conda是一个开源的软件包管理系统和环境管理系统，可以管理不同的Python版本环境，不同的环境之间是互相隔离，互不影响的。\n查看环境# 查看当前环境conda info --env\n克隆环境# 假设已有环境名为A，需要生成的环境名为B：conda create -n B --clone A# 如果特殊环境为Base，需要采用以下方式conda update condaconda create -n &lt;my_env&gt; --clone rootconda create -n torch_env --clone rootconda install pytorch=0.4.0 cuda90 -c pytorch# 用于复制环境到新的机器conda list --explicit &gt; spec-file.txtconda create --name &lt;my_env&gt; --file spec-file.txt\n创建环境# 创建一个环境名为py34，指定Python版本是3.4 #（不用管是3.4.x，conda会为我们自动寻找3.4.x中的最新版本） conda create --name py34 python=3.4 # 通过创建环境，我们可以使用不同版本的Python conda create --name py27 python=2.7\n激活环境# 在windows环境下使用activate激活 activate py34# 在Linux &amp; Mac中使用source activate激活 source activate py34 \n退出环境# 在windows环境下使用deactivate &lt;my_env&gt;# 在Linux &amp; Mac中使用source deactivate &lt;my_env&gt;\n删除环境# 如果你不想要这个名为py34的环境，可以通过以下命令删除这个环境。 conda remove -n py34 --all # 可以通过以下命令查看已有的环境列表，现在py34已经不在这个列表里。 conda info -e\n配置镜像# 显示目前的channels conda config --show channels # 切换默认镜像源 conda config --remove-key channels# 删除指定channel conda config --remove channels_URL # Windows 用户无法直接创建名为 .condarc 的文件，使用以下命令 C:\\Users\\用户名\\.condarcconda config --set show_channel_urls yes# 中科大镜像源 conda config --add channels https://mirrors.ustc.edu.cn/anaconda/pkgs/main/ conda config --add channels https://mirrors.ustc.edu.cn/anaconda/pkgs/free/conda config --add channels https://mirrors.ustc.edu.cn/anaconda/cloud/conda-forge/ conda config --add channels https://mirrors.ustc.edu.cn/anaconda/cloud/msys2/ conda config --add channels https://mirrors.ustc.edu.cn/anaconda/cloud/bioconda/ conda config --add channels https://mirrors.ustc.edu.cn/anaconda/cloud/menpo/ conda config --add channels https://mirrors.ustc.edu.cn/anaconda/cloud/  # 北京外国语大学源 conda config --add channels https://mirrors.bfsu.edu.cn/anaconda/pkgs/main conda config --add channels https://mirrors.bfsu.edu.cn/anaconda/pkgs/free conda config --add channels https://mirrors.bfsu.edu.cn/anaconda/pkgs/r conda config --add channels https://mirrors.bfsu.edu.cn/anaconda/pkgs/pro conda config --add channels https://mirrors.bfsu.edu.cn/anaconda/pkgs/msys2# 清华源 conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/mainconda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/r conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/pro conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/msys2 \nTensorflow环境安装查看Tensorflow版本和安装指定版本。\n# 查询tensorflow-gpu的版本conda search tensorflow-gpu# 指定版本进行安装conda install tensorflow-gpu==1.13.1\n\n安装过程中会安装cudatoolkit-10.0.130和cudnn-7.6.5。 \n\n执行下述命令查看tf版本和GPU是否生效。\n查看是否安装成功import tensorflow as tf# 打印Tensorflow版本print(tf.__version__)# 打印是否支持GPUprint(tf.test.is_gpu_available())\n根据图片打印结果，成功安装tf 1.13.1 版本，同时GPU安装生效。\n\nPytorch环境安装执行下述命令安装Pytorch。\nconda install pytorch==1.7.0 torchvision==0.8.0 torchaudio==0.7.0 cudatoolkit=10.1 -c pytorch\n执行下述命令查看torch版本和GPU是否生效。\nimport torchprint(torch.__version__)print(torch.cuda.is_available())\n根据图片打印结果，成功安装Pytorch 1.7.0 版本，同时GPU安装生效。\n\n参考\nMore info: 阿尔发go：conda常用命令\n\nMore info: 卖萌哥：conda的安装与使用\n\nMore info: 无聊就看书：Tensorflow-gpu1.13.1 和 Tensorflow-gpu2.0.0共存之安装教程\n\n\n","categories":["深度学习"],"tags":["Conda"]},{"title":"如何使用Github Pages搭建个人博客","url":"/2022/05/04/%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8Github-Pages%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/","content":"技术原理GitHub Pages 是直接从 GitHub 存储库托管的静态网站。 但它们不仅仅是静态文件的集合。 通过利用 Jekyll 和 Liquid 等网站生成技术，开发人员可定义被处理为完整静态网站的动态模板。 每次将更改提交到与网站关联的源分支时，都会使用最新更新重新生成该更改，并自动将其发布到目标 URL。\nGitHub Pages 是直接从 GitHub 存储库托管的免费静态网站。 使用 YAML 和 Markdown 等标准技术，任何人都可以在几分钟内生成和维护网站。\n使用环境参考如何使用本地插入图片https://github.com/xcodebuild/hexo-asset-imagehttps://blog.csdn.net/fitnig/article/details/106522811\n"},{"title":"snippets","url":"/2022/05/04/snippets/","content":"Sklearn的dataset转为dataframeimport pandas as pdfrom sklearn import datasetsdef sklearn_to_df(sklearn_dataset):    df = pd.DataFrame(sklearn_dataset.data, columns=sklearn_dataset.feature_names)    df[&#x27;TARGET&#x27;] = pd.Series(sklearn_dataset.target)    return dfdf_boston = sklearn_to_df(datasets.load_boston())print(df_boston.head())\npymysql读取mysql数据转化为dataframe\nimport pymysqlimport pandas as pddef load_data_frame_from_mysql():    conn = pymysql.connect(host=&quot;127.0.0.1&quot;,                           port=3307,                           user=&quot;utest&quot;,                           password=&quot;123456xyq&quot;,                           db=&quot;sakila&quot;,                           charset=&quot;utf8&quot;)    sql = &quot;SELECT * FROM sakila.payment&quot;    data_frame = pd.read_sql(sql, conn)    return data_framepdata = load_data_frame_from_mysql()print(pdata.head())\nImage处理代码# -*-coding: utf-8 -*-&quot;&quot;&quot;    @Project: IntelligentManufacture    @File   : image_processing.py    @Author : panjq    @E-mail : pan_jinquan@163.com    @Date   : 2019-02-14 15:34:50&quot;&quot;&quot; import osimport globimport cv2import numpy as npimport matplotlib.pyplot as plt def show_image(title, image):    &#x27;&#x27;&#x27;    调用matplotlib显示RGB图片    :param title: 图像标题    :param image: 图像的数据    :return:    &#x27;&#x27;&#x27;    # plt.figure(&quot;show_image&quot;)    # print(image.dtype)    plt.imshow(image)    plt.axis(&#x27;on&#x27;)  # 关掉坐标轴为 off    plt.title(title)  # 图像题目    plt.show() def cv_show_image(title, image):    &#x27;&#x27;&#x27;    调用OpenCV显示RGB图片    :param title: 图像标题    :param image: 输入RGB图像    :return:    &#x27;&#x27;&#x27;    channels=image.shape[-1]    if channels==3:        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)  # 将BGR转为RGB    cv2.imshow(title,image)    cv2.waitKey(0) def read_image(filename, resize_height=None, resize_width=None, normalization=False):    &#x27;&#x27;&#x27;    读取图片数据,默认返回的是uint8,[0,255]    :param filename:    :param resize_height:    :param resize_width:    :param normalization:是否归一化到[0.,1.0]    :return: 返回的RGB图片数据    &#x27;&#x27;&#x27;     bgr_image = cv2.imread(filename)    # bgr_image = cv2.imread(filename,cv2.IMREAD_IGNORE_ORIENTATION|cv2.IMREAD_COLOR)    if bgr_image is None:        print(&quot;Warning:不存在:&#123;&#125;&quot;, filename)        return None    if len(bgr_image.shape) == 2:  # 若是灰度图则转为三通道        print(&quot;Warning:gray image&quot;, filename)        bgr_image = cv2.cvtColor(bgr_image, cv2.COLOR_GRAY2BGR)     rgb_image = cv2.cvtColor(bgr_image, cv2.COLOR_BGR2RGB)  # 将BGR转为RGB    # show_image(filename,rgb_image)    # rgb_image=Image.open(filename)    rgb_image = resize_image(rgb_image,resize_height,resize_width)    rgb_image = np.asanyarray(rgb_image)    if normalization:        # 不能写成:rgb_image=rgb_image/255        rgb_image = rgb_image / 255.0    # show_image(&quot;src resize image&quot;,image)    return rgb_image def fast_read_image_roi(filename, orig_rect, ImreadModes=cv2.IMREAD_COLOR, normalization=False):    &#x27;&#x27;&#x27;    快速读取图片的方法    :param filename: 图片路径    :param orig_rect:原始图片的感兴趣区域rect    :param ImreadModes: IMREAD_UNCHANGED                        IMREAD_GRAYSCALE                        IMREAD_COLOR                        IMREAD_ANYDEPTH                        IMREAD_ANYCOLOR                        IMREAD_LOAD_GDAL                        IMREAD_REDUCED_GRAYSCALE_2                        IMREAD_REDUCED_COLOR_2                        IMREAD_REDUCED_GRAYSCALE_4                        IMREAD_REDUCED_COLOR_4                        IMREAD_REDUCED_GRAYSCALE_8                        IMREAD_REDUCED_COLOR_8                        IMREAD_IGNORE_ORIENTATION    :param normalization: 是否归一化    :return: 返回感兴趣区域ROI    &#x27;&#x27;&#x27;    # 当采用IMREAD_REDUCED模式时，对应rect也需要缩放    scale=1    if ImreadModes == cv2.IMREAD_REDUCED_COLOR_2 or ImreadModes == cv2.IMREAD_REDUCED_COLOR_2:        scale=1/2    elif ImreadModes == cv2.IMREAD_REDUCED_GRAYSCALE_4 or ImreadModes == cv2.IMREAD_REDUCED_COLOR_4:        scale=1/4    elif ImreadModes == cv2.IMREAD_REDUCED_GRAYSCALE_8 or ImreadModes == cv2.IMREAD_REDUCED_COLOR_8:        scale=1/8    rect = np.array(orig_rect)*scale    rect = rect.astype(int).tolist()    bgr_image = cv2.imread(filename,flags=ImreadModes)     if bgr_image is None:        print(&quot;Warning:不存在:&#123;&#125;&quot;, filename)        return None    if len(bgr_image.shape) == 3:  #        rgb_image = cv2.cvtColor(bgr_image, cv2.COLOR_BGR2RGB)  # 将BGR转为RGB    else:        rgb_image=bgr_image #若是灰度图    rgb_image = np.asanyarray(rgb_image)    if normalization:        # 不能写成:rgb_image=rgb_image/255        rgb_image = rgb_image / 255.0    roi_image=get_rect_image(rgb_image , rect)    # show_image_rect(&quot;src resize image&quot;,rgb_image,rect)    # cv_show_image(&quot;reROI&quot;,roi_image)    return roi_image def resize_image(image,resize_height, resize_width):    &#x27;&#x27;&#x27;    :param image:    :param resize_height:    :param resize_width:    :return:    &#x27;&#x27;&#x27;    image_shape=np.shape(image)    height=image_shape[0]    width=image_shape[1]    if (resize_height is None) and (resize_width is None):#错误写法：resize_height and resize_width is None        return image    if resize_height is None:        resize_height=int(height*resize_width/width)    elif resize_width is None:        resize_width=int(width*resize_height/height)    image = cv2.resize(image, dsize=(resize_width, resize_height))    return imagedef scale_image(image,scale):    &#x27;&#x27;&#x27;    :param image:    :param scale: (scale_w,scale_h)    :return:    &#x27;&#x27;&#x27;    image = cv2.resize(image,dsize=None, fx=scale[0],fy=scale[1])    return image  def get_rect_image(image,rect):    &#x27;&#x27;&#x27;    :param image:    :param rect: [x,y,w,h]    :return:    &#x27;&#x27;&#x27;    x, y, w, h=rect    cut_img = image[y:(y+ h),x:(x+w)]    return cut_imgdef scale_rect(orig_rect,orig_shape,dest_shape):    &#x27;&#x27;&#x27;    对图像进行缩放时，对应的rectangle也要进行缩放    :param orig_rect: 原始图像的rect=[x,y,w,h]    :param orig_shape: 原始图像的维度shape=[h,w]    :param dest_shape: 缩放后图像的维度shape=[h,w]    :return: 经过缩放后的rectangle    &#x27;&#x27;&#x27;    new_x=int(orig_rect[0]*dest_shape[1]/orig_shape[1])    new_y=int(orig_rect[1]*dest_shape[0]/orig_shape[0])    new_w=int(orig_rect[2]*dest_shape[1]/orig_shape[1])    new_h=int(orig_rect[3]*dest_shape[0]/orig_shape[0])    dest_rect=[new_x,new_y,new_w,new_h]    return dest_rect def show_image_rect(win_name,image,rect):    &#x27;&#x27;&#x27;    :param win_name:    :param image:    :param rect:    :return:    &#x27;&#x27;&#x27;    x, y, w, h=rect    point1=(x,y)    point2=(x+w,y+h)    cv2.rectangle(image, point1, point2, (0, 0, 255), thickness=2)    cv_show_image(win_name, image) def rgb_to_gray(image):    image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)    return image def save_image(image_path, rgb_image,toUINT8=True):    if toUINT8:        rgb_image = np.asanyarray(rgb_image * 255, dtype=np.uint8)    if len(rgb_image.shape) == 2:  # 若是灰度图则转为三通道        bgr_image = cv2.cvtColor(rgb_image, cv2.COLOR_GRAY2BGR)    else:        bgr_image = cv2.cvtColor(rgb_image, cv2.COLOR_RGB2BGR)    cv2.imwrite(image_path, bgr_image) def combime_save_image(orig_image, dest_image, out_dir,name,prefix):    &#x27;&#x27;&#x27;    命名标准：out_dir/name_prefix.jpg    :param orig_image:    :param dest_image:    :param image_path:    :param out_dir:    :param prefix:    :return:    &#x27;&#x27;&#x27;    dest_path = os.path.join(out_dir, name + &quot;_&quot;+prefix+&quot;.jpg&quot;)    save_image(dest_path, dest_image)     dest_image = np.hstack((orig_image, dest_image))    save_image(os.path.join(out_dir, &quot;&#123;&#125;_src_&#123;&#125;.jpg&quot;.format(name,prefix)), dest_image)\n","categories":["Snippet"],"tags":["Snippet","Python"]}]