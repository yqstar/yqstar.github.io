[{"title":"Pytorch系列自学教程(2):深度学习“Hello World”之Mnist图像分类","url":"/2022/05/11/Pytorch%E7%B3%BB%E5%88%97%E8%87%AA%E5%AD%A6%E6%95%99%E7%A8%8B-2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E2%80%9CHello-World%E2%80%9D%E4%B9%8BMnist%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/","content":"本章节主要通过深度学习“Hello World”之Mnist图像分类，学会深度学习的基本链路，快速搭建个人的Baseline模型，包括数据加载、数据可视化、模型构建、模型训练评估和模型结果指标展示。\nMnist数据集是手写数字0~9的MNIST数据集，包含60,000个用于训练的训练集和10,000个用于测试的测试集。这些数字已被大小归一化，并以固定尺寸的图像为中心。对于尝试学习深度学习技术的人来说，这是一个非常棒的数据集，同时可以花费最少时间来进行预处理和格式化。详细：Mnist官网\n环境配置环境配置主要包括：操作系统，显卡，深度学习Pytorch等配置如下。\n系统：Windows 11 - WSL2 系统显卡：NVIDIA GeForce RTX 3060python: 3.6.13pytorch: 1.7.1cudatoolkit: 11.0.221torchvision: 0.8.2\n导入包环境本文使用的Python Package 主要有Pytorch的深度学习框架，torchvision用于加载Mnist数据集，matplotlib用于可视化展示数据集和展示训练结果等。\nfrom torchvision import datasets, transformsfrom torch.utils.data import DataLoaderimport torchimport torch.optim as optimimport torch.nn as nnimport torch.nn.functional as Fimport numpy as npimport randomimport matplotlib.pyplot as pltfrom torchinfo import summary\n构建baseline模型核心是快速跑通完整链路，同时在Baseline的基础上迭代更新有合适的对比标准，方便验证算法模型的稳定性和正确性。为保证训练模型的可重复性，我们需要进行一些配置。全部配置主要分为三部分，具体如下：\n\nCUDNN配置，CUDNN中对卷积操作进行优化，牺牲精度来换取计算效率。\nPytorch在运行中会有很多随机初始化操作，所以需要固定随机种子。\nPython &amp; Numpy也需要固定对应的随机种子。\n注意，如果Dataloader采用了多线程(num_workers &gt; 1), 那么由于读取数据的顺序不同，最终运行结果也会有差异。也就是说，改变num_workers参数，也会对实验结果产生影响。\n\n# 保证试验结果的稳定性seed = 0random.seed(seed)np.random.seed(seed)torch.manual_seed(seed)torch.cuda.manual_seed_all(seed)torch.backends.cudnn.benchmark = Falsetorch.backends.cudnn.deterministic = True# 配置Cuda参数is_cuda = Falseif torch.cuda.is_available():    is_cuda = True# 模型参数batch_size = 32num_epochs = 2\n模型数据本章节就不详细讲解，大家可以查看前一章的讲解。More Info: 数据加载\n# 构建Datasetmnist_train_dataset = datasets.MNIST(root=r&#x27;./data&#x27;,                              transform=transforms.ToTensor(),                              train=True,                              download=True)mnist_test_dataset = datasets.MNIST(root=r&#x27;./data&#x27;,                              transform=transforms.ToTensor(),                              train=False,                              download=True)# 构建Dataloadermnist_train_loader = DataLoader(mnist_train_dataset,batch_size=32,shuffle=True)mnist_test_loader = DataLoader(mnist_test_dataset,batch_size=32,shuffle=True)\n为更好地看到我们需要处理什么样的数据，我们可以用一些可视化的手段展示我们的数据。\n# 图片查看def plot_image(image,batch_size=32):    x_batch,y_batch = image[0],image[1]    f = plt.figure(figsize=(300,300))    # mean = 0.1307    # std = 0.3081    # image = ((image * mean) + std)    # plt.imshow(image, cmap=&#x27;gray&#x27;)    for i in range(batch_size):        image_tx = x_batch.numpy()[i]        # image_ty = y_batch.numpy()[i]        np.math.sqrt(32)        # Debug, plot figure        sub_size = int(np.math.sqrt(32))+1        f.add_subplot(sub_size,sub_size, i + 1)        # plt.subplot_mosaic        plt.imshow(image_tx[0], cmap=&#x27;gray&#x27;)    plt.show()sample_image_batch = next(iter(mnist_train_loader))plot_image(sample_image_batch)\n图片展示结果如下：\n\n模型构建# 构建网络class MnistNet(nn.Module):    def __init__(self):        super().__init__()        self.conv1 = nn.Conv2d(in_channels=1,out_channels=32,kernel_size= 3)        self.conv2 = nn.Conv2d(in_channels= 32,out_channels= 64,kernel_size= 3)        self.dropout = nn.Dropout2d(0.25)        self.fc1 = nn.Linear(9216, 128)        self.fc2 = nn.Linear(128, 10)    def forward(self, x):        x = self.conv1(x)        x = F.relu(x)        x = self.conv2(x)        x = F.relu(x)        x = F.max_pool2d(x, 2)        x = self.dropout(x)        x = x.view(-1, 9216)        x = self.fc1(x)        x = F.relu(x)        x = self.fc2(x)        x = F.log_softmax(x, dim=1)        return x\n在进行模型训练过程中，我们可以使用以下代码，查看构建的模型结构，目前torchinfo仅能展示 torch.nn 模块下的模型结构，采用 torch.nn.functional 构造的函数是无法显示的。\nsummary(model, input_size=(batch_size, 1, 28, 28),depth=4)\n\n模型训练模型训练函数如果模型中有BN层(Batch Normalization）和Dropout，需要在训练时添加model.train()，在测试时添加model.eval()。其中model.train()是保证BN层用每一批数据的均值和方差，而model.eval()是保证BN用全部训练数据的均值和方差；而对于Dropout，model.train()是随机取一部分网络连接来训练更新参数，而model.eval()是利用到了所有网络连接。\n# 模型训练函数def fit_train(model,data_loader):    model.train()    running_loss = 0    running_correct = 0    for batch_idx, (data, target) in enumerate(data_loader):        if is_cuda:            data, target = data.cuda(), target.cuda()        optimizer.zero_grad()        output = model(data)        loss = F.nll_loss(output, target)        running_loss += F.nll_loss(output ,target ,reduction=&#x27;sum&#x27;).item()        preds = output.data.max(1, keepdim=True)[1]        running_correct += preds.eq(target.data.view_as(preds)).cpu().sum()        loss.backward()        optimizer.step()    loss = running_loss/len(data_loader.dataset)    accuracy = 100. * running_correct/len(data_loader.dataset)    print(f&quot;Train loss is &#123;loss:&#123;5&#125;.&#123;2&#125;&#125; and Train accuracy is &#123;accuracy:&#123;10&#125;.&#123;4&#125;&#125; %&quot;)    return loss, accuracy# 模型评估函数def fit_eval(model,data_loader):    model.eval()    running_loss = 0    running_correct = 0    for batch_idx, (data, target) in enumerate(data_loader):        if is_cuda:            data, target = data.cuda(), target.cuda()        output = model(data)        loss = F.nll_loss(output, target)        running_loss += F.nll_loss(output ,target ,reduction=&#x27;sum&#x27;).item()        preds = output.data.max(1, keepdim=True)[1]        running_correct += preds.eq(target.data.view_as(preds)).cpu().sum()    loss = running_loss/len(data_loader.dataset)    accuracy = 100. * running_correct/len(data_loader.dataset)    print(f&quot;Eval loss is &#123;loss:&#123;5&#125;.&#123;2&#125;&#125; and Eval accuracy is &#123;accuracy:&#123;10&#125;.&#123;4&#125;&#125; %&quot;)    return loss, accuracy\n初始化模型和配置优化函数。\nmodel = MnistNet()if is_cuda:    model.cuda()optimizer = optim.SGD(model.parameters(),lr=0.01)\n模型评估train_losses, train_accuracy = [], []val_losses, val_accuracy = [], []for epoch in range(1, 20):    epoch_loss, epoch_accuracy = fit_train(model, mnist_train_loader)    val_epoch_loss, val_epoch_accuracy = fit_eval(model, mnist_test_loader)    train_losses.append(epoch_loss)    train_accuracy.append(epoch_accuracy)    val_losses.append(val_epoch_loss)    val_accuracy.append(val_epoch_accuracy)\n\nplt.plot(range(1,len(train_losses)+1),train_losses,&#x27;bo&#x27;,label = &#x27;training loss&#x27;)plt.plot(range(1,len(val_losses)+1),val_losses,&#x27;r&#x27;,label = &#x27;validation loss&#x27;)plt.legend()plt.show()\n\nplt.plot(range(1,len(train_accuracy)+1),train_accuracy,&#x27;bo&#x27;,label = &#x27;train accuracy&#x27;)plt.plot(range(1,len(val_accuracy)+1),val_accuracy,&#x27;r&#x27;,label = &#x27;val accuracy&#x27;)plt.legend()plt.show()\n\n探索到此为止，已经可以使用自己数据玩耍各种Demo，快（苦）乐（逼）地进行炼丹之路。道路阻且长，行则将至，但行好事莫问前程。\n\nDemo模型还可以修改Loss函数，优化函数和模型结构？\n除了Torchinfo，是否可以使用Tensorboard等可视化工具管理模型数据的可视化数据呢？\nDemo模型离生产上线还有多远距离？如何上线部署模型呢？如何实现从Mysql等数据库到线上模型调用呢？任何的代码是否都应该以能够终端使用为目的？\n\n正如，人往往会对未知的事情产生恐惧，因为结局是未知的。所以当一切不再未知的时候，那么是不是就不会产生恐惧呢？\n","categories":["深度学习"],"tags":["Pytorch_Tutorial"]},{"title":"Pytorch系列自学教程(1):数据加载之Dataset和DataLoader使用","url":"/2022/05/05/Pytorch%E7%B3%BB%E5%88%97%E8%87%AA%E5%AD%A6%E6%95%99%E7%A8%8B-1-%E6%95%B0%E6%8D%AE%E5%8A%A0%E8%BD%BD%E4%B9%8BDataset%E5%92%8CDataLoader%E4%BD%BF%E7%94%A8/","content":"深度学习模型，区别于其他的机器学习模型，一方面，模型训练所需的数据量通常是非常大的，是无法一次性加载到内存中；另一方面，模型训练多采用基于梯度下降的优化方法对模型的权重和偏置进行逐步调整的，不可能一次性地在模型中进行正向传播和反向传播。通常，我们需要进行数据加载和预处理处理，将其封装成适合迭代训练的形式，具体会对整个数据进行随机打乱，然后将原始数据处理成一个一个的Batch，然后送到模型中进行训练。\n深度学习模型流程中一般都是先解决数据加载问题，包括数据的输入问题和预处理问题，数据加载处理在深度学习链路中起着非常重要的基础作用。这篇文章将介绍Pytorch对自定义数据集进行封装的方法。\nDataset、Batch、Iteration和Epoch的关系在介绍如何使用Pytorch加载数据前，简单介绍下，Dataset，Batch，Iteration 和 Epoch 的区别和关系。\n\n\n\n\n名词\n解释                                             \n\n\n\n\n  Dataset\n待训练的全量数据集                                      \n\n\n   Batch\n待训练全量数据集的一小部分样本对模型进行一次反向传播参数更新，这一小部分样本称为“一个Batch” \n\n\n Iteration\n使用一个Batch数据对模型进行一次参数更新的过程，称之为“一次Iteration”             \n\n\n   Epoch\n待训练全量数据集对模型进行一次完整的参数更新，称之为“一个Epoch”               \n\n\n\n\n假设DatasetSize=10，BatchSize=3，那么每个Epoch会执行4个Iteration，对应四个Batch，每个BatchSize大小分别包括3，3，3和1个样本。\n\nPytoch数据处理：DataSet和DataLoaderPytorch提供了几个有用的工具：torch.utils.data.Dataset类和torch.utils.data.DataLoader类，用于数据读取和预处理。基本流程是先把原始数据转变成torch.utils.data.Dataset类，随后把得到的torch.utils.data.Dataset类当作一个参数传递给torch.utils.data.DataLoader类，得到一个数据加载器，这个数据加载器每次可以返回一个Batch的数据供模型训练使用。\ntorch.utils.data.Dataset类torch.utils.data.Dataset是代表这一数据的抽象类，你可以自己定义数据类，继承和重写这个抽象类，只需要定义init，len和getitem这三个魔法函数,其中：\n\n_init_()：用于初始化原始数据的路径和文件名等。\n_len_()：用于返回数据集中的样本总个数。\n_getitem_()：用于返回指定索引的样本所对应的输入变量与输出变量。\n\n# class CustomDataset(torch.utils.data.Dataset):#需要继承data.Dataset#     def __init__(self):#         # TODO#         # 1. Initialize file path or list of file names.#         pass#     def __getitem__(self, index):#         # TODO#         # 1. Read one data from file (e.g. using numpy.fromfile, PIL.Image.open).#         # 2. Preprocess the data (e.g. torchvision.Transform).#         # 3. Return a data pair (e.g. image and label).#         #这里需要注意的是，第一步：read one data，是一个data#         pass#     def __len__(self):#         # You should change 0 to the total size of your dataset.#         pass\n用原始数据构造出来的Dataset子类可以理解成一个静态数据池，这个数据池使得我们可以用索引得到某个样本数据，而想要该数据池流动起来，源源不断地输出Batch供给给模型训练，还需要下一个工具DataLoader类。所以我们把创建的Dataset子类当参数传入即将构建的DataLoader类才是使用Dataset子类最终目的。\ntorch.utils.data.DataLoader类DataLoader(object)可用参数：\n\ndataset(Dataset): 传入的数据集。\nbatch_size(int, optional): 每个batch有多少样本。\nshuffle(bool, optional): 在每个epoch开始时，对数据进行打乱排序。\nsampler(Sampler, optional): 自定义从数据集中取样本的策略，如果指定这个参数，那么shuffle必须为False。\nbatch_sampler(Sampler, optional): 与sampler类似，但是一次只返回一个batch的indices（索引），需要注意的是，一旦指定了这个参数，那么batch_size,shuffle,sampler,drop_last就不能再配置（互斥）。\nnum_workers (int, optional): 决定了有几个进程来处理data loading。0意味着所有的数据都会被load进主进程。（默认为0）\ncollate_fn (callable, optional): 将一个list的sample组成一个mini-batch的函数。\npin_memory (bool, optional)： 如果设置为True，那么data loader将会在返回它们之前，将tensors拷贝到CUDA中的固定内存中。\ndrop_last (bool, optional):如果设置为True：这个是对最后的未完成的batch来说的，比如batch_size设置为64，而一个epoch只有100个样本，那么训练时后面36个样本会被丢弃。 如果为False（默认），那么会继续正常执行，只是最后的batch_size会小一点。\ntimeout(numeric, optional):如果是正数，表明等待从worker进程中收集一个batch等待时间，若超出设定时间还没有收集到，那就不收集这个内容。这个numeric应总是大于等于0。默认为0\nworker_init_fn (callable, optional): 每个worker初始化函数。 \n\n实例txt数据读取使用个人创建的txt文件数据，进行数据读取操作。\nimport torchimport numpy as npfrom torch.utils.data import Dataset, DataLoaderclass SampleTxtDataset(Dataset):    def __init__(self):        # 数据文件地址        self.txt_file_path = &quot;./sample_easy_data.txt&quot;    def __getitem__(self, item):        txt_data = np.loadtxt(self.txt_file_path, delimiter=&quot;,&quot;)        self._x = torch.from_numpy(txt_data[:, :2])        self._y = torch.from_numpy(txt_data[:, 2])        return self._x[item], self._y[item]    def __len__(self):        txt_data = np.loadtxt(self.txt_file_path, delimiter=&quot;,&quot;)        self._len = len(txt_data)        return self._lensample_txt_dataset = SampleTxtDataset()print(&quot;Data Size:&quot;,len(sample_txt_dataset))print(&quot;First Sample:&quot;,next(iter(sample_txt_dataset)))print(&quot;First Sample&#x27;s Type:&quot;,type(next(iter(sample_txt_dataset))[0]))sample_dataloader = DataLoader(dataset=sample_txt_dataset, batch_size=3, shuffle=True)num_epochs = 4for epoch in range(num_epochs):    for iteration, (batch_x, batch_y) in enumerate(sample_dataloader):        print(&#x27;Epoch: &#x27;, epoch, &#x27;| Iteration: &#x27;, iteration, &#x27;| batch x: &#x27;, batch_x.numpy(), &#x27;| batch y: &#x27;, batch_y.numpy())\nDataset的示例结果：\n\nDataLoader的示例结果：\n\ncsv文件读取使用常见离线数据csv文件进行数据加载和预处理。\nimport torchimport pandas as pdfrom torch.utils.data import Dataset, DataLoaderclass SampleCsvDataset(Dataset):    def __init__(self):        self.csv_file_path = &quot;./sample_boston.csv&quot;    def __getitem__(self, item):        raw_data = pd.read_csv(self.csv_file_path)        raw_data_shape = raw_data.shape        self._x  = torch.from_numpy(raw_data.iloc[:,:raw_data_shape[1]-1].values)        self._y  = torch.from_numpy(raw_data.iloc[:,raw_data_shape[1]-1].values)        return self._x[item], self._y[item]    def __len__(self):        raw_data = pd.read_csv(self.csv_file_path)        raw_data_shape = raw_data.shape        self._len = raw_data_shape[0]        return self._lensample_csv_dataset = SampleCsvDataset()print(&quot;Data Size:&quot;,len(sample_csv_dataset))print(&quot;First Sample:&quot;,next(iter(sample_csv_dataset)))print(&quot;First Sample&#x27;s Type:&quot;,type(next(iter(sample_csv_dataset))[0]))sample_dataloader = DataLoader(dataset=sample_csv_dataset, batch_size=3, shuffle=True)num_epochs = 4for epoch in range(num_epochs):    for iteration, (batch_x, batch_y) in enumerate(sample_dataloader):        print(&#x27;Epoch: &#x27;, epoch, &#x27;| Iteration: &#x27;, iteration, &#x27;| batch x: &#x27;, batch_x.numpy(), &#x27;| batch y: &#x27;, batch_y.numpy())\nmysql数据读取生产落地数据多为数据库，本文也针对常见Mysql数据库进行了数据加载，使用的是MYSQL8.0数据库的示例数据库sakila.payment表进行数据读取演示。\nimport torchimport pandas as pdimport pymysqlfrom torch.utils.data import Dataset, DataLoaderclass SampleMysqlDataset(Dataset):    def __init__(self):        # 初始化MySQL数据库连接配置参数        self.mysql_host = &quot;localhost&quot;        self.mysql_port = 3307        self.mysql_user = &quot;utest&quot;        self.mysql_password = &quot;123456xyq&quot;        self.mysql_db = &quot;sakila&quot;        self.mysql_table = &quot;payment&quot;        self.mysql_charset = &quot;utf8&quot;        self.mysql_sql_data = &quot;select payment_id, customer_id, staff_id, rental_id, amount from sakila.payment&quot;        self.mysql_sql_cnt = &quot;select count(*) from sakila.payment&quot;    def __getitem__(self, item):        # 创建数据库连接        conn = pymysql.connect(host=self.mysql_host,                        port=self.mysql_port,                        user=self.mysql_user,                        password=self.mysql_password,                        db=self.mysql_db,                        charset=self.mysql_charset)        raw_dataframe = pd.read_sql(self.mysql_sql_data, conn)        raw_dataframe_shape = raw_dataframe.shape        self._x  = torch.from_numpy(raw_dataframe.iloc[:,:raw_dataframe_shape[1]-1].values)        self._y  = torch.from_numpy(raw_dataframe.iloc[:,raw_dataframe_shape[1]-1].values)        return self._x[item], self._y[item]    def __len__(self):        # 创建数据库连接        conn = pymysql.connect(host=self.mysql_host,                        port=self.mysql_port,                        user=self.mysql_user,                        password=self.mysql_password,                        db=self.mysql_db,                        charset=self.mysql_charset)        raw_dataframe = pd.read_sql(self.mysql_sql_data, conn)        raw_dataframe_shape = raw_dataframe.shape        self._len = raw_dataframe_shape[0]        return self._lensample_mysql_dataset = SampleMysqlDataset()print(&quot;Data Size:&quot;,len(sample_mysql_dataset))print(&quot;First Sample:&quot;,next(iter(sample_mysql_dataset)))print(&quot;First Sample&#x27;s Type:&quot;,type(next(iter(sample_mysql_dataset))[0]))sample_dataloader = DataLoader(dataset=sample_mysql_dataset, batch_size=3, shuffle=True)num_epochs = 4for epoch in range(num_epochs):    for iteration, (batch_x, batch_y) in enumerate(sample_dataloader):        print(&#x27;Epoch: &#x27;, epoch, &#x27;| Iteration: &#x27;, iteration, &#x27;| batch x: &#x27;, batch_x.numpy(), &#x27;| batch y: &#x27;, batch_y.numpy())\n使用pytorch自带数据集为方便快速试验，Pytorch也集成了常见的数据集在torchaudio，torchtext和torchvision中，本代码使用torchvision读取常用的图像算法数据集MNIST，具体代码如下。\nfrom torchvision import datasets, transformsfrom torch.utils.data import DataLoader# 导入训练集sample_mnist_dataset = datasets.MNIST(root=r&#x27;./data&#x27;,                              transform=transforms.ToTensor(),                              train=True,                              download=True)print(&quot;Data Size:&quot;,len(sample_mnist_dataset))print(&quot;First Sample:&quot;,next(iter(sample_mnist_dataset)))print(&quot;First Sample&#x27;s Type:&quot;,type(next(iter(sample_mnist_dataset))[0]))sample_dataloader = DataLoader(dataset=sample_mnist_dataset, batch_size=3, shuffle=True)num_epochs = 4for epoch in range(num_epochs):    for iter, (batch_x, batch_y) in enumerate(sample_dataloader):        print(&#x27;Epoch: &#x27;, epoch, &#x27;| Iteration: &#x27;, iter, &#x27;| batch x: &#x27;, batch_x.numpy(), &#x27;| batch y: &#x27;, batch_y.numpy())\n探索\n生产读取大量数据无法一次加载到内存该如何操作呢？\n\n如何使用TorchData进行数据读取和预处理？\n\n\n参考More info: pan_jinquan：Dataset, DataLoader产生自定义的训练数据\nMore info: 夜和大帝：Dataset类的使用\nMore info: setail：pytorch_tutorial\nMore info: Ericam_：十分钟搞懂Pytorch如何读取MNIST数据集\nMore info: Chenllliang：两文读懂PyTorch中Dataset与DataLoader（一）打造自己的数据集\nMore Info: cici_iii：大数据量下如何使用Dataset和IterDataset构建数据集\nMore Info: csdn-WJW: 如何划分训练集，测试集和验证集\n","categories":["深度学习"],"tags":["Pytorch_Tutorial"]},{"title":"Pytorch系列自学教程(3):深度学习之Mnist图像分类TorchServe部署","url":"/2022/05/15/Pytorch%E7%B3%BB%E5%88%97%E8%87%AA%E5%AD%A6%E6%95%99%E7%A8%8B-3-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B9%8BMnist%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BBTorchServe%E9%83%A8%E7%BD%B2/","content":"使用 PyTorch 训练好 Demo 模型，如何部署到生产环境提供用于提供服务呢？\n未完待续 ！！！\n参考More info: Chenglu：如何部署PyTorch模型More info: TorchServeMore info: TorchServe_Mnist ExampleMore info: 随便写点笔记\n","tags":["Pytorch_Tutorial"]},{"title":"Pytorch系列自学教程(4):深度学习之序列模型","url":"/2022/06/01/Pytorch%E7%B3%BB%E5%88%97%E8%87%AA%E5%AD%A6%E6%95%99%E7%A8%8B-4-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%BA%8F%E5%88%97%E6%A8%A1%E5%9E%8B/","content":"https://www.zhihu.com/question/279046805/answer/1153623199\n","tags":["Pytorch_Tutorial"]},{"title":"Windows系统使用Conda配置深度学习环境","url":"/2022/05/01/Windows%E7%B3%BB%E7%BB%9F%E4%BD%BF%E7%94%A8Conda%E9%85%8D%E7%BD%AE%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83/","content":"Conda环境管理Conda是一个开源的软件包管理系统和环境管理系统，可以管理不同的Python版本环境，不同的环境之间是互相隔离，互不影响的。\n查看环境# 查看当前环境conda info --env\n克隆环境# 假设已有环境名为A，需要生成的环境名为B：conda create -n B --clone A# 如果特殊环境为Base，需要采用以下方式conda update condaconda create -n &lt;my_env&gt; --clone rootconda create -n torch_env --clone rootconda install pytorch=0.4.0 cuda90 -c pytorch# 用于复制环境到新的机器conda list --explicit &gt; spec-file.txtconda create --name &lt;my_env&gt; --file spec-file.txt\n创建环境# 创建一个环境名为py34，指定Python版本是3.4 #（不用管是3.4.x，conda会为我们自动寻找3.4.x中的最新版本） conda create --name py34 python=3.4 # 通过创建环境，我们可以使用不同版本的Python conda create --name py27 python=2.7\n激活环境# 在windows环境下使用activate激活 activate py34# 在Linux &amp; Mac中使用source activate激活 source activate py34 \n退出环境# 在windows环境下使用deactivate &lt;my_env&gt;# 在Linux &amp; Mac中使用source deactivate &lt;my_env&gt;\n删除环境# 如果你不想要这个名为py34的环境，可以通过以下命令删除这个环境。 conda remove -n py34 --all # 可以通过以下命令查看已有的环境列表，现在py34已经不在这个列表里。 conda info -e\n配置镜像# 显示目前的channels conda config --show channels # 切换默认镜像源 conda config --remove-key channels# 删除指定channel conda config --remove channels_URL # Windows 用户无法直接创建名为 .condarc 的文件，使用以下命令 C:\\Users\\用户名\\.condarcconda config --set show_channel_urls yes# 中科大镜像源 conda config --add channels https://mirrors.ustc.edu.cn/anaconda/pkgs/main/ conda config --add channels https://mirrors.ustc.edu.cn/anaconda/pkgs/free/conda config --add channels https://mirrors.ustc.edu.cn/anaconda/cloud/conda-forge/ conda config --add channels https://mirrors.ustc.edu.cn/anaconda/cloud/msys2/ conda config --add channels https://mirrors.ustc.edu.cn/anaconda/cloud/bioconda/ conda config --add channels https://mirrors.ustc.edu.cn/anaconda/cloud/menpo/ conda config --add channels https://mirrors.ustc.edu.cn/anaconda/cloud/  # 北京外国语大学源 conda config --add channels https://mirrors.bfsu.edu.cn/anaconda/pkgs/main conda config --add channels https://mirrors.bfsu.edu.cn/anaconda/pkgs/free conda config --add channels https://mirrors.bfsu.edu.cn/anaconda/pkgs/r conda config --add channels https://mirrors.bfsu.edu.cn/anaconda/pkgs/pro conda config --add channels https://mirrors.bfsu.edu.cn/anaconda/pkgs/msys2# 清华源 conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/mainconda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/r conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/pro conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/msys2 \nTensorflow环境安装查看Tensorflow版本和安装指定版本。\n# 查询tensorflow-gpu的版本conda search tensorflow-gpu# 指定版本进行安装conda install tensorflow-gpu==1.13.1\n\n安装过程中会安装cudatoolkit-10.0.130和cudnn-7.6.5。 \n\n执行下述命令查看tf版本和GPU是否生效。\n查看是否安装成功import tensorflow as tf# 打印Tensorflow版本print(tf.__version__)# 打印是否支持GPUprint(tf.test.is_gpu_available())\n根据图片打印结果，成功安装tf 1.13.1 版本，同时GPU安装生效。\n\nPytorch环境安装执行下述命令安装Pytorch。\nconda install pytorch==1.7.0 torchvision==0.8.0 torchaudio==0.7.0 cudatoolkit=10.1 -c pytorch\n执行下述命令查看torch版本和GPU是否生效。\nimport torchprint(torch.__version__)print(torch.cuda.is_available())\n根据图片打印结果，成功安装Pytorch 1.7.0 版本，同时GPU安装生效。\n\n参考\nMore info: 阿尔发go：conda常用命令\n\nMore info: 卖萌哥：conda的安装与使用\n\nMore info: 无聊就看书：Tensorflow-gpu1.13.1 和 Tensorflow-gpu2.0.0共存之安装教程\n\n\n","tags":["Conda"]},{"title":"snippets","url":"/2022/05/01/snippets/","content":"本博客的目的主要是为了收集一些常用代码，或者一些有意思的代码，方便后续的工作学习使用。\nSklearn的dataset转为dataframe\nimport pandas as pdfrom sklearn import datasetsdef sklearn_to_df(sklearn_dataset):    df = pd.DataFrame(sklearn_dataset.data, columns=sklearn_dataset.feature_names)    df[&#x27;TARGET&#x27;] = pd.Series(sklearn_dataset.target)    return dfdf_boston = sklearn_to_df(datasets.load_boston())print(df_boston.head())\npymysql读取mysql数据转化为dataframe\nimport pymysqlimport pandas as pddef load_data_frame_from_mysql():    conn = pymysql.connect(host=&quot;127.0.0.1&quot;,                           port=3307,                           user=&quot;utest&quot;,                           password=&quot;123456xyq&quot;,                           db=&quot;sakila&quot;,                           charset=&quot;utf8&quot;)    sql = &quot;SELECT * FROM sakila.payment&quot;    data_frame = pd.read_sql(sql, conn)    return data_framepdata = load_data_frame_from_mysql()print(pdata.head())\nImage处理代码# -*-coding: utf-8 -*-&quot;&quot;&quot;    @Project: IntelligentManufacture    @File   : image_processing.py    @Author : panjq    @E-mail : pan_jinquan@163.com    @Date   : 2019-02-14 15:34:50&quot;&quot;&quot; import osimport globimport cv2import numpy as npimport matplotlib.pyplot as plt def show_image(title, image):    &#x27;&#x27;&#x27;    调用matplotlib显示RGB图片    :param title: 图像标题    :param image: 图像的数据    :return:    &#x27;&#x27;&#x27;    # plt.figure(&quot;show_image&quot;)    # print(image.dtype)    plt.imshow(image)    plt.axis(&#x27;on&#x27;)  # 关掉坐标轴为 off    plt.title(title)  # 图像题目    plt.show() def cv_show_image(title, image):    &#x27;&#x27;&#x27;    调用OpenCV显示RGB图片    :param title: 图像标题    :param image: 输入RGB图像    :return:    &#x27;&#x27;&#x27;    channels=image.shape[-1]    if channels==3:        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)  # 将BGR转为RGB    cv2.imshow(title,image)    cv2.waitKey(0) def read_image(filename, resize_height=None, resize_width=None, normalization=False):    &#x27;&#x27;&#x27;    读取图片数据,默认返回的是uint8,[0,255]    :param filename:    :param resize_height:    :param resize_width:    :param normalization:是否归一化到[0.,1.0]    :return: 返回的RGB图片数据    &#x27;&#x27;&#x27;     bgr_image = cv2.imread(filename)    # bgr_image = cv2.imread(filename,cv2.IMREAD_IGNORE_ORIENTATION|cv2.IMREAD_COLOR)    if bgr_image is None:        print(&quot;Warning:不存在:&#123;&#125;&quot;, filename)        return None    if len(bgr_image.shape) == 2:  # 若是灰度图则转为三通道        print(&quot;Warning:gray image&quot;, filename)        bgr_image = cv2.cvtColor(bgr_image, cv2.COLOR_GRAY2BGR)     rgb_image = cv2.cvtColor(bgr_image, cv2.COLOR_BGR2RGB)  # 将BGR转为RGB    # show_image(filename,rgb_image)    # rgb_image=Image.open(filename)    rgb_image = resize_image(rgb_image,resize_height,resize_width)    rgb_image = np.asanyarray(rgb_image)    if normalization:        # 不能写成:rgb_image=rgb_image/255        rgb_image = rgb_image / 255.0    # show_image(&quot;src resize image&quot;,image)    return rgb_image def fast_read_image_roi(filename, orig_rect, ImreadModes=cv2.IMREAD_COLOR, normalization=False):    &#x27;&#x27;&#x27;    快速读取图片的方法    :param filename: 图片路径    :param orig_rect:原始图片的感兴趣区域rect    :param ImreadModes: IMREAD_UNCHANGED                        IMREAD_GRAYSCALE                        IMREAD_COLOR                        IMREAD_ANYDEPTH                        IMREAD_ANYCOLOR                        IMREAD_LOAD_GDAL                        IMREAD_REDUCED_GRAYSCALE_2                        IMREAD_REDUCED_COLOR_2                        IMREAD_REDUCED_GRAYSCALE_4                        IMREAD_REDUCED_COLOR_4                        IMREAD_REDUCED_GRAYSCALE_8                        IMREAD_REDUCED_COLOR_8                        IMREAD_IGNORE_ORIENTATION    :param normalization: 是否归一化    :return: 返回感兴趣区域ROI    &#x27;&#x27;&#x27;    # 当采用IMREAD_REDUCED模式时，对应rect也需要缩放    scale=1    if ImreadModes == cv2.IMREAD_REDUCED_COLOR_2 or ImreadModes == cv2.IMREAD_REDUCED_COLOR_2:        scale=1/2    elif ImreadModes == cv2.IMREAD_REDUCED_GRAYSCALE_4 or ImreadModes == cv2.IMREAD_REDUCED_COLOR_4:        scale=1/4    elif ImreadModes == cv2.IMREAD_REDUCED_GRAYSCALE_8 or ImreadModes == cv2.IMREAD_REDUCED_COLOR_8:        scale=1/8    rect = np.array(orig_rect)*scale    rect = rect.astype(int).tolist()    bgr_image = cv2.imread(filename,flags=ImreadModes)     if bgr_image is None:        print(&quot;Warning:不存在:&#123;&#125;&quot;, filename)        return None    if len(bgr_image.shape) == 3:  #        rgb_image = cv2.cvtColor(bgr_image, cv2.COLOR_BGR2RGB)  # 将BGR转为RGB    else:        rgb_image=bgr_image #若是灰度图    rgb_image = np.asanyarray(rgb_image)    if normalization:        # 不能写成:rgb_image=rgb_image/255        rgb_image = rgb_image / 255.0    roi_image=get_rect_image(rgb_image , rect)    # show_image_rect(&quot;src resize image&quot;,rgb_image,rect)    # cv_show_image(&quot;reROI&quot;,roi_image)    return roi_image def resize_image(image,resize_height, resize_width):    &#x27;&#x27;&#x27;    :param image:    :param resize_height:    :param resize_width:    :return:    &#x27;&#x27;&#x27;    image_shape=np.shape(image)    height=image_shape[0]    width=image_shape[1]    if (resize_height is None) and (resize_width is None):#错误写法：resize_height and resize_width is None        return image    if resize_height is None:        resize_height=int(height*resize_width/width)    elif resize_width is None:        resize_width=int(width*resize_height/height)    image = cv2.resize(image, dsize=(resize_width, resize_height))    return imagedef scale_image(image,scale):    &#x27;&#x27;&#x27;    :param image:    :param scale: (scale_w,scale_h)    :return:    &#x27;&#x27;&#x27;    image = cv2.resize(image,dsize=None, fx=scale[0],fy=scale[1])    return image  def get_rect_image(image,rect):    &#x27;&#x27;&#x27;    :param image:    :param rect: [x,y,w,h]    :return:    &#x27;&#x27;&#x27;    x, y, w, h=rect    cut_img = image[y:(y+ h),x:(x+w)]    return cut_imgdef scale_rect(orig_rect,orig_shape,dest_shape):    &#x27;&#x27;&#x27;    对图像进行缩放时，对应的rectangle也要进行缩放    :param orig_rect: 原始图像的rect=[x,y,w,h]    :param orig_shape: 原始图像的维度shape=[h,w]    :param dest_shape: 缩放后图像的维度shape=[h,w]    :return: 经过缩放后的rectangle    &#x27;&#x27;&#x27;    new_x=int(orig_rect[0]*dest_shape[1]/orig_shape[1])    new_y=int(orig_rect[1]*dest_shape[0]/orig_shape[0])    new_w=int(orig_rect[2]*dest_shape[1]/orig_shape[1])    new_h=int(orig_rect[3]*dest_shape[0]/orig_shape[0])    dest_rect=[new_x,new_y,new_w,new_h]    return dest_rect def show_image_rect(win_name,image,rect):    &#x27;&#x27;&#x27;    :param win_name:    :param image:    :param rect:    :return:    &#x27;&#x27;&#x27;    x, y, w, h=rect    point1=(x,y)    point2=(x+w,y+h)    cv2.rectangle(image, point1, point2, (0, 0, 255), thickness=2)    cv_show_image(win_name, image) def rgb_to_gray(image):    image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)    return image def save_image(image_path, rgb_image,toUINT8=True):    if toUINT8:        rgb_image = np.asanyarray(rgb_image * 255, dtype=np.uint8)    if len(rgb_image.shape) == 2:  # 若是灰度图则转为三通道        bgr_image = cv2.cvtColor(rgb_image, cv2.COLOR_GRAY2BGR)    else:        bgr_image = cv2.cvtColor(rgb_image, cv2.COLOR_RGB2BGR)    cv2.imwrite(image_path, bgr_image) def combime_save_image(orig_image, dest_image, out_dir,name,prefix):    &#x27;&#x27;&#x27;    命名标准：out_dir/name_prefix.jpg    :param orig_image:    :param dest_image:    :param image_path:    :param out_dir:    :param prefix:    :return:    &#x27;&#x27;&#x27;    dest_path = os.path.join(out_dir, name + &quot;_&quot;+prefix+&quot;.jpg&quot;)    save_image(dest_path, dest_image)     dest_image = np.hstack((orig_image, dest_image))    save_image(os.path.join(out_dir, &quot;&#123;&#125;_src_&#123;&#125;.jpg&quot;.format(name,prefix)), dest_image)\n","categories":["Snippet"],"tags":["Snippet","Python"]},{"title":"使用GithubPages搭建个人静态博客","url":"/2022/05/01/%E4%BD%BF%E7%94%A8GithubPages%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E9%9D%99%E6%80%81%E5%8D%9A%E5%AE%A2/","content":"原理GitHub Pages 是使用 GitHub 存储仓库托管静态网站，使用 YAML 和 Markdown 等标准技术，任何人都可以在几分钟内生成和维护网站，但它不仅仅是静态文件的集合。通过利用 Jekyll 和 Liquid 等网站生成技术，开发人员可定义完整静态网站的动态模板。每次将更改提交到与网站关联的源代码分支时，都会使用源代码分支的最新代码配置重新生成静态网页，Github 自动将其发布到目标 URL。欢迎关注：我的博客。\n环境配置操作系统：Windows11 -&gt; WSL2 -&gt; Ubuntu 22.04 LTSNode.js: v16.15.0Npm: 8.5.5\n操作部署安装NVM在安装nvm之前简单介绍下nvm，nodejs和npm之间的关系。\n\nnvm：nodejs 的版本管理工具。\nnodejs：项目开发所需要的代码库。\nnpm：nodejs 包管理工具，npm 管理nodejs中的第三方插件。\n\n参考 NPM-GITHUB，使用以下命令安装nvm。\nwget -qO- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.1/install.sh | bash\n安装过程Info截图如下：\n\n判断nvm安装是否成功,可以使用以下命令查看nvm的版本信息。\nnvm -v\n\n安装NODEJS使用 nvm install 命令可以安装指定版本的NodeJs，本次安装v16版本，执行以下命令。\nnvm install 16\n通过下述命令查看node和npm的版本。\nnode -vnpm -v\n可查看到Node和npm的版本。\n\n安装Hexo和配置安装Hexo命令行Hexo是一个快速、简洁且高效的博客框架，官方提供一个命令行工具，用于快速创建项目、页面、编译、部署Hexo博客，安装命令行工具。\nnpm install -g hexo-cli\n初始化本地运行接下来我们使用 Hexo 命令行创建一个项目，并将其在本地跑起来，整体跑通看看。\n首先使用如下命令创建项目：hexo init {blog_name}，这里的 blog_name 就是博客名，我这里要创建 hexo_blog 的博客，我就把项目取名为 hexo_blog ，命令如下：hexo init hexo_blog。\nhexo init &#123;blog_name&#125;cd &#123;blog_name&#125;npm installhexo server\nhexo_blog 文件夹下就会出现 Hexo 的初始化文件，包括 themes、scaffolds、source 等文件夹。\n\n接下来我们首先进入新生成的文件夹里面，然后调用 Hexo 的 generate 命令，将 Hexo 编译生成 HTML 代码，命令如下：hexo generate可以看到输出结果里面包含了 js、css、font 等内容，并发现他们都处在了项目根目录下的 public 文件夹下面了。\n然后使用 Hexo 提供的 server 命令把博客在本地运行起来，命令如下：hexo server 运行之后命令行输出如下：\nINFO  Start processingINFO  Hexois running at http://localhost:4000 . Press Ctrl+C to stop.\n本地 4000 端口上就可以查看博客站点，如图所示：\n\n主题配置登录官网Hexo官网,然后点击主题页面Theme主题，选择一个喜欢主题，我这边选择的主题是keep主题。执行安装命令，会将主题文件安装在node_modules文件夹中。\nnpm install hexo-theme-keep --save\n\n执行hexo server命令执行本地查看。\n可以看出此时数据已经更新成keep主题。\n部署到Github执行部署到Github需要使用hexo-deployer-git插件\nnpm install hexo-deployer-git --save\n安装好hexo-deployer-git后可以进行文件的配置。具体配置如下：\n\n在这之前需要github配置相应的仓库，我配置的仓库名为：yqstar.github.io.\n\n\n参考MoreInfo:hexo-asset-image插件MoreInfo:如何使用本地插入图片\n"}]