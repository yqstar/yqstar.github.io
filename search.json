[{"title":"Pytorchç³»åˆ—è‡ªå­¦æ•™ç¨‹(1):æ•°æ®åŠ è½½ä¹‹Datasetå’ŒDataLoaderä½¿ç”¨","url":"/2022/05/22/Pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%95%99%E7%A8%8B-1-%E6%95%B0%E6%8D%AE%E5%8A%A0%E8%BD%BD%E4%B9%8BDataset%E5%92%8CDataLoader%E4%BD%BF%E7%94%A8/","content":"æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼ŒåŒºåˆ«äºå…¶ä»–çš„æœºå™¨å­¦ä¹ æ¨¡å‹ï¼Œä¸€æ–¹é¢ï¼Œæ¨¡å‹è®­ç»ƒæ‰€éœ€çš„æ•°æ®é‡é€šå¸¸æ˜¯éå¸¸å¤§çš„ï¼Œæ˜¯æ— æ³•ä¸€æ¬¡æ€§åŠ è½½åˆ°å†…å­˜ä¸­ï¼›å¦ä¸€æ–¹é¢ï¼Œæ¨¡å‹è®­ç»ƒå¤šé‡‡ç”¨åŸºäºæ¢¯åº¦ä¸‹é™çš„ä¼˜åŒ–æ–¹æ³•å¯¹æ¨¡å‹çš„æƒé‡å’Œåç½®è¿›è¡Œé€æ­¥è°ƒæ•´çš„ï¼Œä¸å¯èƒ½ä¸€æ¬¡æ€§åœ°åœ¨æ¨¡å‹ä¸­è¿›è¡Œæ­£å‘ä¼ æ’­å’Œåå‘ä¼ æ’­ã€‚é€šå¸¸ï¼Œæˆ‘ä»¬éœ€è¦è¿›è¡Œæ•°æ®åŠ è½½å’Œé¢„å¤„ç†å¤„ç†ï¼Œå°†å…¶å°è£…æˆé€‚åˆè¿­ä»£è®­ç»ƒçš„å½¢å¼ï¼Œå…·ä½“ä¼šå¯¹æ•´ä¸ªæ•°æ®è¿›è¡Œéšæœºæ‰“ä¹±ï¼Œç„¶åå°†åŸå§‹æ•°æ®å¤„ç†æˆä¸€ä¸ªä¸€ä¸ªçš„Batchï¼Œç„¶åé€åˆ°æ¨¡å‹ä¸­è¿›è¡Œè®­ç»ƒã€‚\næ·±åº¦å­¦ä¹ æ¨¡å‹æµç¨‹ä¸­ä¸€èˆ¬éƒ½æ˜¯å…ˆè§£å†³æ•°æ®åŠ è½½é—®é¢˜ï¼ŒåŒ…æ‹¬æ•°æ®çš„è¾“å…¥é—®é¢˜å’Œé¢„å¤„ç†é—®é¢˜ï¼Œæ•°æ®åŠ è½½å¤„ç†åœ¨æ·±åº¦å­¦ä¹ é“¾è·¯ä¸­èµ·ç€éå¸¸é‡è¦çš„åŸºç¡€ä½œç”¨ã€‚è¿™ç¯‡æ–‡ç« å°†ä»‹ç»Pytorchå¯¹è‡ªå®šä¹‰æ•°æ®é›†è¿›è¡Œå°è£…çš„æ–¹æ³•ã€‚\nDatasetã€Batchã€Iterationå’ŒEpochçš„å…³ç³»åœ¨ä»‹ç»å¦‚ä½•ä½¿ç”¨PytorchåŠ è½½æ•°æ®å‰ï¼Œç®€å•ä»‹ç»ä¸‹ï¼ŒDatasetï¼ŒBatchï¼ŒIteration å’Œ Epoch çš„åŒºåˆ«å’Œå…³ç³»ã€‚\n\n\n\n\nåè¯\nè§£é‡Š\n\n\n\n\n  Dataset\nå¾…è®­ç»ƒçš„å…¨é‡æ•°æ®é›†\n\n\n   Batch\nå¾…è®­ç»ƒå…¨é‡æ•°æ®é›†çš„ä¸€å°éƒ¨åˆ†æ ·æœ¬å¯¹æ¨¡å‹è¿›è¡Œä¸€æ¬¡åå‘ä¼ æ’­å‚æ•°æ›´æ–°ï¼Œè¿™ä¸€å°éƒ¨åˆ†æ ·æœ¬ç§°ä¸ºâ€œä¸€ä¸ªBatchâ€\n\n\n Iteration\nä½¿ç”¨ä¸€ä¸ªBatchæ•°æ®å¯¹æ¨¡å‹è¿›è¡Œä¸€æ¬¡å‚æ•°æ›´æ–°çš„è¿‡ç¨‹ï¼Œç§°ä¹‹ä¸ºâ€œä¸€æ¬¡Iterationâ€\n\n\n   Epoch\nå¾…è®­ç»ƒå…¨é‡æ•°æ®é›†å¯¹æ¨¡å‹è¿›è¡Œä¸€æ¬¡å®Œæ•´çš„å‚æ•°æ›´æ–°ï¼Œç§°ä¹‹ä¸ºâ€œä¸€ä¸ªEpochâ€\n\n\n\n\nå‡è®¾DatasetSize=10ï¼ŒBatchSize=3ï¼Œé‚£ä¹ˆæ¯ä¸ªEpochä¼šæ‰§è¡Œ4ä¸ªIterationï¼Œå¯¹åº”å››ä¸ªBatchï¼Œæ¯ä¸ªBatchSizeå¤§å°åˆ†åˆ«åŒ…æ‹¬3ï¼Œ3ï¼Œ3å’Œ1ä¸ªæ ·æœ¬ã€‚\n\nPytochæ•°æ®å¤„ç†ï¼šDataSetå’ŒDataLoaderPytorchæä¾›äº†å‡ ä¸ªæœ‰ç”¨çš„å·¥å…·ï¼štorch.utils.data.Datasetç±»å’Œtorch.utils.data.DataLoaderç±»ï¼Œç”¨äºæ•°æ®è¯»å–å’Œé¢„å¤„ç†ã€‚åŸºæœ¬æµç¨‹æ˜¯å…ˆæŠŠåŸå§‹æ•°æ®è½¬å˜æˆtorch.utils.data.Datasetç±»ï¼ŒéšåæŠŠå¾—åˆ°çš„torch.utils.data.Datasetç±»å½“ä½œä¸€ä¸ªå‚æ•°ä¼ é€’ç»™torch.utils.data.DataLoaderç±»ï¼Œå¾—åˆ°ä¸€ä¸ªæ•°æ®åŠ è½½å™¨ï¼Œè¿™ä¸ªæ•°æ®åŠ è½½å™¨æ¯æ¬¡å¯ä»¥è¿”å›ä¸€ä¸ªBatchçš„æ•°æ®ä¾›æ¨¡å‹è®­ç»ƒä½¿ç”¨ã€‚\ntorch.utils.data.Datasetç±»torch.utils.data.Datasetæ˜¯ä»£è¡¨è¿™ä¸€æ•°æ®çš„æŠ½è±¡ç±»ï¼Œä½ å¯ä»¥è‡ªå·±å®šä¹‰æ•°æ®ç±»ï¼Œç»§æ‰¿å’Œé‡å†™è¿™ä¸ªæŠ½è±¡ç±»ï¼Œåªéœ€è¦å®šä¹‰initï¼Œlenå’Œgetitemè¿™ä¸‰ä¸ªé­”æ³•å‡½æ•°,å…¶ä¸­ï¼š\n\n_init_()ï¼šç”¨äºåˆå§‹åŒ–åŸå§‹æ•°æ®çš„è·¯å¾„å’Œæ–‡ä»¶åç­‰ã€‚\n_len_()ï¼šç”¨äºè¿”å›æ•°æ®é›†ä¸­çš„æ ·æœ¬æ€»ä¸ªæ•°ã€‚\n_getitem_()ï¼šç”¨äºè¿”å›æŒ‡å®šç´¢å¼•çš„æ ·æœ¬æ‰€å¯¹åº”çš„è¾“å…¥å˜é‡ä¸è¾“å‡ºå˜é‡ã€‚\n\n# class CustomDataset(torch.utils.data.Dataset):#éœ€è¦ç»§æ‰¿data.Dataset#     def __init__(self):#         # TODO#         # 1. Initialize file path or list of file names.#         pass#     def __getitem__(self, index):#         # TODO#         # 1. Read one data from file (e.g. using numpy.fromfile, PIL.Image.open).#         # 2. Preprocess the data (e.g. torchvision.Transform).#         # 3. Return a data pair (e.g. image and label).#         #è¿™é‡Œéœ€è¦æ³¨æ„çš„æ˜¯ï¼Œç¬¬ä¸€æ­¥ï¼šread one dataï¼Œæ˜¯ä¸€ä¸ªdata#         pass#     def __len__(self):#         # You should change 0 to the total size of your dataset.#         pass\nç”¨åŸå§‹æ•°æ®æ„é€ å‡ºæ¥çš„Datasetå­ç±»å¯ä»¥ç†è§£æˆä¸€ä¸ªé™æ€æ•°æ®æ± ï¼Œè¿™ä¸ªæ•°æ®æ± ä½¿å¾—æˆ‘ä»¬å¯ä»¥ç”¨ç´¢å¼•å¾—åˆ°æŸä¸ªæ ·æœ¬æ•°æ®ï¼Œè€Œæƒ³è¦è¯¥æ•°æ®æ± æµåŠ¨èµ·æ¥ï¼Œæºæºä¸æ–­åœ°è¾“å‡ºBatchä¾›ç»™ç»™æ¨¡å‹è®­ç»ƒï¼Œè¿˜éœ€è¦ä¸‹ä¸€ä¸ªå·¥å…·DataLoaderç±»ã€‚æ‰€ä»¥æˆ‘ä»¬æŠŠåˆ›å»ºçš„Datasetå­ç±»å½“å‚æ•°ä¼ å…¥å³å°†æ„å»ºçš„DataLoaderç±»æ‰æ˜¯ä½¿ç”¨Datasetå­ç±»æœ€ç»ˆç›®çš„ã€‚\ntorch.utils.data.DataLoaderç±»DataLoader(object)å¯ç”¨å‚æ•°:\n\ndataset(Dataset): ä¼ å…¥çš„æ•°æ®é›†ã€‚\nbatch_size(int, optional): æ¯ä¸ªbatchæœ‰å¤šå°‘æ ·æœ¬ã€‚\nshuffle(bool, optional): åœ¨æ¯ä¸ªepochå¼€å§‹æ—¶ï¼Œå¯¹æ•°æ®è¿›è¡Œæ‰“ä¹±æ’åºã€‚\nsampler(Sampler, optional): è‡ªå®šä¹‰ä»æ•°æ®é›†ä¸­å–æ ·æœ¬çš„ç­–ç•¥ï¼Œå¦‚æœæŒ‡å®šè¿™ä¸ªå‚æ•°ï¼Œé‚£ä¹ˆshuffleå¿…é¡»ä¸ºFalseã€‚\nbatch_sampler(Sampler, optional): ä¸samplerç±»ä¼¼ï¼Œä½†æ˜¯ä¸€æ¬¡åªè¿”å›ä¸€ä¸ªbatchçš„indicesï¼ˆç´¢å¼•ï¼‰ï¼Œéœ€è¦æ³¨æ„çš„æ˜¯ï¼Œä¸€æ—¦æŒ‡å®šäº†è¿™ä¸ªå‚æ•°ï¼Œé‚£ä¹ˆbatch_size,shuffle,sampler,drop_lastå°±ä¸èƒ½å†é…ç½®ï¼ˆäº’æ–¥ï¼‰ã€‚\nnum_workers (int, optional): å†³å®šäº†æœ‰å‡ ä¸ªè¿›ç¨‹æ¥å¤„ç†data loadingã€‚0æ„å‘³ç€æ‰€æœ‰çš„æ•°æ®éƒ½ä¼šè¢«loadè¿›ä¸»è¿›ç¨‹ã€‚ï¼ˆé»˜è®¤ä¸º0ï¼‰\ncollate_fn (callable, optional): å°†ä¸€ä¸ªlistçš„sampleç»„æˆä¸€ä¸ªmini-batchçš„å‡½æ•°ã€‚\npin_memory (bool, optional)ï¼š å¦‚æœè®¾ç½®ä¸ºTrueï¼Œé‚£ä¹ˆdata loaderå°†ä¼šåœ¨è¿”å›å®ƒä»¬ä¹‹å‰ï¼Œå°†tensorsæ‹·è´åˆ°CUDAä¸­çš„å›ºå®šå†…å­˜ä¸­ã€‚\ndrop_last (bool, optional):å¦‚æœè®¾ç½®ä¸ºTrueï¼šè¿™ä¸ªæ˜¯å¯¹æœ€åçš„æœªå®Œæˆçš„batchæ¥è¯´çš„ï¼Œæ¯”å¦‚batch_sizeè®¾ç½®ä¸º64ï¼Œè€Œä¸€ä¸ªepochåªæœ‰100ä¸ªæ ·æœ¬ï¼Œé‚£ä¹ˆè®­ç»ƒæ—¶åé¢36ä¸ªæ ·æœ¬ä¼šè¢«ä¸¢å¼ƒã€‚ å¦‚æœä¸ºFalseï¼ˆé»˜è®¤ï¼‰ï¼Œé‚£ä¹ˆä¼šç»§ç»­æ­£å¸¸æ‰§è¡Œï¼Œåªæ˜¯æœ€åçš„batch_sizeä¼šå°ä¸€ç‚¹ã€‚\ntimeout(numeric, optional):å¦‚æœæ˜¯æ­£æ•°ï¼Œè¡¨æ˜ç­‰å¾…ä»workerè¿›ç¨‹ä¸­æ”¶é›†ä¸€ä¸ªbatchç­‰å¾…æ—¶é—´ï¼Œè‹¥è¶…å‡ºè®¾å®šæ—¶é—´è¿˜æ²¡æœ‰æ”¶é›†åˆ°ï¼Œé‚£å°±ä¸æ”¶é›†è¿™ä¸ªå†…å®¹ã€‚è¿™ä¸ªnumericåº”æ€»æ˜¯å¤§äºç­‰äº0ã€‚é»˜è®¤ä¸º0\nworker_init_fn (callable, optional): æ¯ä¸ªworkeråˆå§‹åŒ–å‡½æ•°ã€‚\n\nå®ä¾‹txtæ•°æ®è¯»å–ä½¿ç”¨ä¸ªäººåˆ›å»ºçš„txtæ–‡ä»¶æ•°æ®ï¼Œè¿›è¡Œæ•°æ®è¯»å–æ“ä½œã€‚\nimport torchimport numpy as npfrom torch.utils.data import Dataset, DataLoaderclass SampleTxtDataset(Dataset):    def __init__(self):        # æ•°æ®æ–‡ä»¶åœ°å€        self.txt_file_path = &quot;./sample_easy_data.txt&quot;    def __getitem__(self, item):        txt_data = np.loadtxt(self.txt_file_path, delimiter=&quot;,&quot;)        self._x = torch.from_numpy(txt_data[:, :2])        self._y = torch.from_numpy(txt_data[:, 2])        return self._x[item], self._y[item]    def __len__(self):        txt_data = np.loadtxt(self.txt_file_path, delimiter=&quot;,&quot;)        self._len = len(txt_data)        return self._lensample_txt_dataset = SampleTxtDataset()print(&quot;Data Size:&quot;,len(sample_txt_dataset))print(&quot;First Sample:&quot;,next(iter(sample_txt_dataset)))print(&quot;First Sample&#x27;s Type:&quot;,type(next(iter(sample_txt_dataset))[0]))sample_dataloader = DataLoader(dataset=sample_txt_dataset, batch_size=3, shuffle=True)num_epochs = 4for epoch in range(num_epochs):    for iteration, (batch_x, batch_y) in enumerate(sample_dataloader):        print(&#x27;Epoch: &#x27;, epoch, &#x27;| Iteration: &#x27;, iteration, &#x27;| batch x: &#x27;, batch_x.numpy(), &#x27;| batch y: &#x27;, batch_y.numpy())\nDatasetçš„ç¤ºä¾‹ç»“æœï¼š\n\nDataLoaderçš„ç¤ºä¾‹ç»“æœï¼š\n\ncsvæ–‡ä»¶è¯»å–ä½¿ç”¨å¸¸è§ç¦»çº¿æ•°æ®csvæ–‡ä»¶è¿›è¡Œæ•°æ®åŠ è½½å’Œé¢„å¤„ç†ã€‚\nimport torchimport pandas as pdfrom torch.utils.data import Dataset, DataLoaderclass SampleCsvDataset(Dataset):    def __init__(self):        self.csv_file_path = &quot;./sample_boston.csv&quot;    def __getitem__(self, item):        raw_data = pd.read_csv(self.csv_file_path)        raw_data_shape = raw_data.shape        self._x  = torch.from_numpy(raw_data.iloc[:,:raw_data_shape[1]-1].values)        self._y  = torch.from_numpy(raw_data.iloc[:,raw_data_shape[1]-1].values)        return self._x[item], self._y[item]    def __len__(self):        raw_data = pd.read_csv(self.csv_file_path)        raw_data_shape = raw_data.shape        self._len = raw_data_shape[0]        return self._lensample_csv_dataset = SampleCsvDataset()print(&quot;Data Size:&quot;,len(sample_csv_dataset))print(&quot;First Sample:&quot;,next(iter(sample_csv_dataset)))print(&quot;First Sample&#x27;s Type:&quot;,type(next(iter(sample_csv_dataset))[0]))sample_dataloader = DataLoader(dataset=sample_csv_dataset, batch_size=3, shuffle=True)num_epochs = 4for epoch in range(num_epochs):    for iteration, (batch_x, batch_y) in enumerate(sample_dataloader):        print(&#x27;Epoch: &#x27;, epoch, &#x27;| Iteration: &#x27;, iteration, &#x27;| batch x: &#x27;, batch_x.numpy(), &#x27;| batch y: &#x27;, batch_y.numpy())\nmysqlæ•°æ®è¯»å–ç”Ÿäº§è½åœ°æ•°æ®å¤šä¸ºæ•°æ®åº“ï¼Œæœ¬æ–‡ä¹Ÿé’ˆå¯¹å¸¸è§Mysqlæ•°æ®åº“è¿›è¡Œäº†æ•°æ®åŠ è½½ï¼Œä½¿ç”¨çš„æ˜¯MYSQL8.0æ•°æ®åº“çš„ç¤ºä¾‹æ•°æ®åº“sakila.paymentè¡¨è¿›è¡Œæ•°æ®è¯»å–æ¼”ç¤ºã€‚\nimport torchimport pandas as pdimport pymysqlfrom torch.utils.data import Dataset, DataLoaderclass SampleMysqlDataset(Dataset):    def __init__(self):        # åˆå§‹åŒ–MySQLæ•°æ®åº“è¿æ¥é…ç½®å‚æ•°        self.mysql_host = &quot;localhost&quot;        self.mysql_port = 3307        self.mysql_user = &quot;utest&quot;        self.mysql_password = &quot;123456xyq&quot;        self.mysql_db = &quot;sakila&quot;        self.mysql_table = &quot;payment&quot;        self.mysql_charset = &quot;utf8&quot;        self.mysql_sql_data = &quot;select payment_id, customer_id, staff_id, rental_id, amount from sakila.payment&quot;        self.mysql_sql_cnt = &quot;select count(*) from sakila.payment&quot;    def __getitem__(self, item):        # åˆ›å»ºæ•°æ®åº“è¿æ¥        conn = pymysql.connect(host=self.mysql_host,                        port=self.mysql_port,                        user=self.mysql_user,                        password=self.mysql_password,                        db=self.mysql_db,                        charset=self.mysql_charset)        raw_dataframe = pd.read_sql(self.mysql_sql_data, conn)        raw_dataframe_shape = raw_dataframe.shape        self._x  = torch.from_numpy(raw_dataframe.iloc[:,:raw_dataframe_shape[1]-1].values)        self._y  = torch.from_numpy(raw_dataframe.iloc[:,raw_dataframe_shape[1]-1].values)        return self._x[item], self._y[item]    def __len__(self):        # åˆ›å»ºæ•°æ®åº“è¿æ¥        conn = pymysql.connect(host=self.mysql_host,                        port=self.mysql_port,                        user=self.mysql_user,                        password=self.mysql_password,                        db=self.mysql_db,                        charset=self.mysql_charset)        raw_dataframe = pd.read_sql(self.mysql_sql_data, conn)        raw_dataframe_shape = raw_dataframe.shape        self._len = raw_dataframe_shape[0]        return self._lensample_mysql_dataset = SampleMysqlDataset()print(&quot;Data Size:&quot;,len(sample_mysql_dataset))print(&quot;First Sample:&quot;,next(iter(sample_mysql_dataset)))print(&quot;First Sample&#x27;s Type:&quot;,type(next(iter(sample_mysql_dataset))[0]))sample_dataloader = DataLoader(dataset=sample_mysql_dataset, batch_size=3, shuffle=True)num_epochs = 4for epoch in range(num_epochs):    for iteration, (batch_x, batch_y) in enumerate(sample_dataloader):        print(&#x27;Epoch: &#x27;, epoch, &#x27;| Iteration: &#x27;, iteration, &#x27;| batch x: &#x27;, batch_x.numpy(), &#x27;| batch y: &#x27;, batch_y.numpy())\nä½¿ç”¨pytorchè‡ªå¸¦æ•°æ®é›†ä¸ºæ–¹ä¾¿å¿«é€Ÿè¯•éªŒï¼ŒPytorchä¹Ÿé›†æˆäº†å¸¸è§çš„æ•°æ®é›†åœ¨torchaudioï¼Œtorchtextå’Œtorchvisionä¸­ï¼Œæœ¬ä»£ç ä½¿ç”¨torchvisionè¯»å–å¸¸ç”¨çš„å›¾åƒç®—æ³•æ•°æ®é›†MNISTï¼Œå…·ä½“ä»£ç å¦‚ä¸‹ã€‚\nfrom torchvision import datasets, transformsfrom torch.utils.data import DataLoader# å¯¼å…¥è®­ç»ƒé›†sample_mnist_dataset = datasets.MNIST(root=r&#x27;./data&#x27;,                              transform=transforms.ToTensor(),                              train=True,                              download=True)print(&quot;Data Size:&quot;,len(sample_mnist_dataset))print(&quot;First Sample:&quot;,next(iter(sample_mnist_dataset)))print(&quot;First Sample&#x27;s Type:&quot;,type(next(iter(sample_mnist_dataset))[0]))sample_dataloader = DataLoader(dataset=sample_mnist_dataset, batch_size=3, shuffle=True)num_epochs = 4for epoch in range(num_epochs):    for iter, (batch_x, batch_y) in enumerate(sample_dataloader):        print(&#x27;Epoch: &#x27;, epoch, &#x27;| Iteration: &#x27;, iter, &#x27;| batch x: &#x27;, batch_x.numpy(), &#x27;| batch y: &#x27;, batch_y.numpy())\næ¢ç´¢å®Œæ•´ä»£ç å·²ä¸Šä¼ Githubï¼Œæœ‰éœ€è¦çš„å¯ä»¥è‡ªè¡Œä¸‹è½½ä»£ç ï¼Œå¦‚æœå¯¹ä½ æœ‰å¸®åŠ©ï¼Œè¯·Starï¼Œå“ˆå“ˆå“ˆå“ˆï¼\n\nç”Ÿäº§è¯»å–å¤§é‡æ•°æ®æ— æ³•ä¸€æ¬¡åŠ è½½åˆ°å†…å­˜è¯¥å¦‚ä½•æ“ä½œå‘¢ï¼Ÿ\n\nå¦‚ä½•ä½¿ç”¨TorchDataè¿›è¡Œæ•°æ®è¯»å–å’Œé¢„å¤„ç†ï¼Ÿ\n\n\nå‚è€ƒMore info: pan_jinquanï¼šDataset, DataLoaderäº§ç”Ÿè‡ªå®šä¹‰çš„è®­ç»ƒæ•°æ®\nMore info: å¤œå’Œå¤§å¸ï¼šDatasetç±»çš„ä½¿ç”¨\nMore info: setailï¼špytorch_tutorial\nMore info: Ericam_ï¼šååˆ†é’Ÿææ‡‚Pytorchå¦‚ä½•è¯»å–MNISTæ•°æ®é›†\nMore info: Chenllliangï¼šä¸¤æ–‡è¯»æ‡‚PyTorchä¸­Datasetä¸DataLoaderï¼ˆä¸€ï¼‰æ‰“é€ è‡ªå·±çš„æ•°æ®é›†\nMore Info: cici_iiiï¼šå¤§æ•°æ®é‡ä¸‹å¦‚ä½•ä½¿ç”¨Datasetå’ŒIterDatasetæ„å»ºæ•°æ®é›†\nMore Info: csdn-WJW: å¦‚ä½•åˆ’åˆ†è®­ç»ƒé›†ï¼Œæµ‹è¯•é›†å’ŒéªŒè¯é›†\n","categories":["æ·±åº¦å­¦ä¹ "],"tags":["Pytorch_Tutorial"]},{"title":"Pytorchç³»åˆ—è‡ªå­¦æ•™ç¨‹(2):æ·±åº¦å­¦ä¹ â€œHello Worldâ€ä¹‹Mnistå›¾åƒåˆ†ç±»","url":"/2022/05/29/Pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%95%99%E7%A8%8B-2-%E2%80%9CHello-World%E2%80%9D%E4%B9%8BMnist%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/","content":"ç®€ä»‹æœ¬ç« èŠ‚ä¸»è¦é€šè¿‡æ·±åº¦å­¦ä¹ â€œHello Worldâ€ä¹‹Mnistå›¾åƒåˆ†ç±»ï¼Œå­¦ä¼šæ·±åº¦å­¦ä¹ çš„åŸºæœ¬é“¾è·¯ï¼Œå¿«é€Ÿæ­å»ºä¸ªäººçš„Baselineæ¨¡å‹ï¼ŒåŒ…æ‹¬æ•°æ®åŠ è½½ã€æ•°æ®å¯è§†åŒ–ã€æ¨¡å‹æ„å»ºã€æ¨¡å‹è®­ç»ƒè¯„ä¼°å’Œæ¨¡å‹ç»“æœæŒ‡æ ‡å±•ç¤ºã€‚\nMnistæ•°æ®é›†æ˜¯æ‰‹å†™æ•°å­—0~9çš„MNISTæ•°æ®é›†ï¼ŒåŒ…å«60,000ä¸ªç”¨äºè®­ç»ƒçš„è®­ç»ƒé›†å’Œ10,000ä¸ªç”¨äºæµ‹è¯•çš„æµ‹è¯•é›†ã€‚è¿™äº›æ•°å­—å·²è¢«å¤§å°å½’ä¸€åŒ–ï¼Œå¹¶ä»¥å›ºå®šå°ºå¯¸çš„å›¾åƒä¸ºä¸­å¿ƒã€‚å¯¹äºå°è¯•å­¦ä¹ æ·±åº¦å­¦ä¹ æŠ€æœ¯çš„äººæ¥è¯´ï¼Œè¿™æ˜¯ä¸€ä¸ªéå¸¸æ£’çš„æ•°æ®é›†ï¼ŒåŒæ—¶å¯ä»¥èŠ±è´¹æœ€å°‘æ—¶é—´æ¥è¿›è¡Œé¢„å¤„ç†å’Œæ ¼å¼åŒ–ã€‚è¯¦ç»†ï¼šMnistå®˜ç½‘\nç¯å¢ƒé…ç½®ç¯å¢ƒé…ç½®ä¸»è¦åŒ…æ‹¬ï¼šæ“ä½œç³»ç»Ÿï¼Œæ˜¾å¡ï¼Œæ·±åº¦å­¦ä¹ Pytorchç­‰é…ç½®å¦‚ä¸‹ã€‚\nç³»ç»Ÿï¼šWindows 11 - WSL2 ç³»ç»Ÿæ˜¾å¡ï¼šNVIDIA GeForce RTX 3060python: 3.6.13pytorch: 1.7.1cudatoolkit: 11.0.221torchvision: 0.8.2\nå¯¼å…¥åŒ…ç¯å¢ƒæœ¬æ–‡ä½¿ç”¨çš„Python Package ä¸»è¦æœ‰Pytorchçš„æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œtorchvisionç”¨äºåŠ è½½Mnistæ•°æ®é›†ï¼Œmatplotlibç”¨äºå¯è§†åŒ–å±•ç¤ºæ•°æ®é›†å’Œå±•ç¤ºè®­ç»ƒç»“æœç­‰ã€‚\nfrom torchvision import datasets, transformsfrom torch.utils.data import DataLoaderimport torchimport torch.optim as optimimport torch.nn as nnimport torch.nn.functional as Fimport numpy as npimport randomimport matplotlib.pyplot as pltfrom torchinfo import summary\næ„å»ºbaselineæ¨¡å‹æ ¸å¿ƒæ˜¯å¿«é€Ÿè·‘é€šå®Œæ•´é“¾è·¯ï¼ŒåŒæ—¶åœ¨Baselineçš„åŸºç¡€ä¸Šè¿­ä»£æ›´æ–°æœ‰åˆé€‚çš„å¯¹æ¯”æ ‡å‡†ï¼Œæ–¹ä¾¿éªŒè¯ç®—æ³•æ¨¡å‹çš„ç¨³å®šæ€§å’Œæ­£ç¡®æ€§ã€‚ä¸ºä¿è¯è®­ç»ƒæ¨¡å‹çš„å¯é‡å¤æ€§ï¼Œæˆ‘ä»¬éœ€è¦è¿›è¡Œä¸€äº›é…ç½®ã€‚å…¨éƒ¨é…ç½®ä¸»è¦åˆ†ä¸ºä¸‰éƒ¨åˆ†ï¼Œå…·ä½“å¦‚ä¸‹ï¼š\n\nCUDNNé…ç½®ï¼ŒCUDNNä¸­å¯¹å·ç§¯æ“ä½œè¿›è¡Œä¼˜åŒ–ï¼Œç‰ºç‰²ç²¾åº¦æ¥æ¢å–è®¡ç®—æ•ˆç‡ã€‚\nPytorchåœ¨è¿è¡Œä¸­ä¼šæœ‰å¾ˆå¤šéšæœºåˆå§‹åŒ–æ“ä½œï¼Œæ‰€ä»¥éœ€è¦å›ºå®šéšæœºç§å­ã€‚\nPython &amp; Numpyä¹Ÿéœ€è¦å›ºå®šå¯¹åº”çš„éšæœºç§å­ã€‚\næ³¨æ„ï¼Œå¦‚æœDataloaderé‡‡ç”¨äº†å¤šçº¿ç¨‹(num_workers &gt; 1), é‚£ä¹ˆç”±äºè¯»å–æ•°æ®çš„é¡ºåºä¸åŒï¼Œæœ€ç»ˆè¿è¡Œç»“æœä¹Ÿä¼šæœ‰å·®å¼‚ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œæ”¹å˜num_workerså‚æ•°ï¼Œä¹Ÿä¼šå¯¹å®éªŒç»“æœäº§ç”Ÿå½±å“ã€‚\n\n# ä¿è¯è¯•éªŒç»“æœçš„ç¨³å®šæ€§seed = 0random.seed(seed)np.random.seed(seed)torch.manual_seed(seed)torch.cuda.manual_seed_all(seed)torch.backends.cudnn.benchmark = Falsetorch.backends.cudnn.deterministic = True# é…ç½®Cudaå‚æ•°is_cuda = Falseif torch.cuda.is_available():    is_cuda = True# æ¨¡å‹å‚æ•°batch_size = 32num_epochs = 2\næ¨¡å‹æ•°æ®æœ¬ç« èŠ‚å°±ä¸è¯¦ç»†è®²è§£ï¼Œå¤§å®¶å¯ä»¥æŸ¥çœ‹å‰ä¸€ç« åšå®¢è®²è§£ã€‚\n# æ„å»ºDatasetmnist_train_dataset = datasets.MNIST(root=r&#x27;./data&#x27;,                              transform=transforms.ToTensor(),                              train=True,                              download=True)mnist_test_dataset = datasets.MNIST(root=r&#x27;./data&#x27;,                              transform=transforms.ToTensor(),                              train=False,                              download=True)# æ„å»ºDataloadermnist_train_loader = DataLoader(mnist_train_dataset,batch_size=32,shuffle=True)mnist_test_loader = DataLoader(mnist_test_dataset,batch_size=32,shuffle=True)\nä¸ºæ›´å¥½åœ°çœ‹åˆ°æˆ‘ä»¬éœ€è¦å¤„ç†ä»€ä¹ˆæ ·çš„æ•°æ®ï¼Œæˆ‘ä»¬å¯ä»¥ç”¨ä¸€äº›å¯è§†åŒ–çš„æ‰‹æ®µå±•ç¤ºæˆ‘ä»¬çš„æ•°æ®ã€‚\n# å›¾ç‰‡æŸ¥çœ‹def plot_image(image,batch_size=32):    x_batch,y_batch = image[0],image[1]    f = plt.figure(figsize=(300,300))    # mean = 0.1307    # std = 0.3081    # image = ((image * mean) + std)    # plt.imshow(image, cmap=&#x27;gray&#x27;)    for i in range(batch_size):        image_tx = x_batch.numpy()[i]        # image_ty = y_batch.numpy()[i]        np.math.sqrt(32)        # Debug, plot figure        sub_size = int(np.math.sqrt(32))+1        f.add_subplot(sub_size,sub_size, i + 1)        # plt.subplot_mosaic        plt.imshow(image_tx[0], cmap=&#x27;gray&#x27;)    plt.show()sample_image_batch = next(iter(mnist_train_loader))plot_image(sample_image_batch)\nå›¾ç‰‡å±•ç¤ºç»“æœå¦‚ä¸‹ï¼š\n\næ¨¡å‹æ„å»º# æ„å»ºç½‘ç»œclass MnistNet(nn.Module):    def __init__(self):        super().__init__()        self.conv1 = nn.Conv2d(in_channels=1,out_channels=32,kernel_size= 3)        self.conv2 = nn.Conv2d(in_channels= 32,out_channels= 64,kernel_size= 3)        self.dropout = nn.Dropout2d(0.25)        self.fc1 = nn.Linear(9216, 128)        self.fc2 = nn.Linear(128, 10)    def forward(self, x):        x = self.conv1(x)        x = F.relu(x)        x = self.conv2(x)        x = F.relu(x)        x = F.max_pool2d(x, 2)        x = self.dropout(x)        x = x.view(-1, 9216)        x = self.fc1(x)        x = F.relu(x)        x = self.fc2(x)        x = F.log_softmax(x, dim=1)        return x\nåœ¨è¿›è¡Œæ¨¡å‹è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä»¥ä¸‹ä»£ç ï¼ŒæŸ¥çœ‹æ„å»ºçš„æ¨¡å‹ç»“æ„ï¼Œç›®å‰torchinfoä»…èƒ½å±•ç¤º torch.nn æ¨¡å—ä¸‹çš„æ¨¡å‹ç»“æ„ï¼Œé‡‡ç”¨ torch.nn.functional æ„é€ çš„å‡½æ•°æ˜¯æ— æ³•æ˜¾ç¤ºçš„ã€‚\nsummary(model, input_size=(batch_size, 1, 28, 28),depth=4)\n\næ¨¡å‹è®­ç»ƒæ¨¡å‹è®­ç»ƒå‡½æ•°å¦‚æœæ¨¡å‹ä¸­æœ‰BNå±‚(Batch Normalizationï¼‰å’ŒDropoutï¼Œéœ€è¦åœ¨è®­ç»ƒæ—¶æ·»åŠ model.train()ï¼Œåœ¨æµ‹è¯•æ—¶æ·»åŠ model.eval()ã€‚å…¶ä¸­model.train()æ˜¯ä¿è¯BNå±‚ç”¨æ¯ä¸€æ‰¹æ•°æ®çš„å‡å€¼å’Œæ–¹å·®ï¼Œè€Œmodel.eval()æ˜¯ä¿è¯BNç”¨å…¨éƒ¨è®­ç»ƒæ•°æ®çš„å‡å€¼å’Œæ–¹å·®ï¼›è€Œå¯¹äºDropoutï¼Œmodel.train()æ˜¯éšæœºå–ä¸€éƒ¨åˆ†ç½‘ç»œè¿æ¥æ¥è®­ç»ƒæ›´æ–°å‚æ•°ï¼Œè€Œmodel.eval()æ˜¯åˆ©ç”¨åˆ°äº†æ‰€æœ‰ç½‘ç»œè¿æ¥ã€‚\n# æ¨¡å‹è®­ç»ƒå‡½æ•°def fit_train(model,data_loader):    model.train()    running_loss = 0    running_correct = 0    for batch_idx, (data, target) in enumerate(data_loader):        if is_cuda:            data, target = data.cuda(), target.cuda()        optimizer.zero_grad()        output = model(data)        loss = F.nll_loss(output, target)        running_loss += F.nll_loss(output ,target ,reduction=&#x27;sum&#x27;).item()        preds = output.data.max(1, keepdim=True)[1]        running_correct += preds.eq(target.data.view_as(preds)).cpu().sum()        loss.backward()        optimizer.step()    loss = running_loss/len(data_loader.dataset)    accuracy = 100. * running_correct/len(data_loader.dataset)    print(f&quot;Train loss is &#123;loss:&#123;5&#125;.&#123;2&#125;&#125; and Train accuracy is &#123;accuracy:&#123;10&#125;.&#123;4&#125;&#125; %&quot;)    return loss, accuracy# æ¨¡å‹è¯„ä¼°å‡½æ•°def fit_eval(model,data_loader):    model.eval()    running_loss = 0    running_correct = 0    for batch_idx, (data, target) in enumerate(data_loader):        if is_cuda:            data, target = data.cuda(), target.cuda()        output = model(data)        loss = F.nll_loss(output, target)        running_loss += F.nll_loss(output ,target ,reduction=&#x27;sum&#x27;).item()        preds = output.data.max(1, keepdim=True)[1]        running_correct += preds.eq(target.data.view_as(preds)).cpu().sum()    loss = running_loss/len(data_loader.dataset)    accuracy = 100. * running_correct/len(data_loader.dataset)    print(f&quot;Eval loss is &#123;loss:&#123;5&#125;.&#123;2&#125;&#125; and Eval accuracy is &#123;accuracy:&#123;10&#125;.&#123;4&#125;&#125; %&quot;)    return loss, accuracy\nåˆå§‹åŒ–æ¨¡å‹å’Œé…ç½®ä¼˜åŒ–å‡½æ•°ã€‚\nmodel = MnistNet()if is_cuda:    model.cuda()optimizer = optim.SGD(model.parameters(),lr=0.01)\næ¨¡å‹è¯„ä¼°train_losses, train_accuracy = [], []val_losses, val_accuracy = [], []for epoch in range(1, 20):    epoch_loss, epoch_accuracy = fit_train(model, mnist_train_loader)    val_epoch_loss, val_epoch_accuracy = fit_eval(model, mnist_test_loader)    train_losses.append(epoch_loss)    train_accuracy.append(epoch_accuracy)    val_losses.append(val_epoch_loss)    val_accuracy.append(val_epoch_accuracy)\n\nplt.plot(range(1,len(train_losses)+1),train_losses,&#x27;bo&#x27;,label = &#x27;training loss&#x27;)plt.plot(range(1,len(val_losses)+1),val_losses,&#x27;r&#x27;,label = &#x27;validation loss&#x27;)plt.legend()plt.show()\n\nplt.plot(range(1,len(train_accuracy)+1),train_accuracy,&#x27;bo&#x27;,label = &#x27;train accuracy&#x27;)plt.plot(range(1,len(val_accuracy)+1),val_accuracy,&#x27;r&#x27;,label = &#x27;val accuracy&#x27;)plt.legend()plt.show()\n\næ¢ç´¢å®Œæ•´ä»£ç å·²ä¸Šä¼ Githubï¼Œæœ‰éœ€è¦çš„å¯ä»¥è‡ªè¡Œä¸‹è½½ä»£ç ï¼Œå¦‚æœå¯¹ä½ æœ‰å¸®åŠ©ï¼Œè¯·Starï¼Œå“ˆå“ˆå“ˆå“ˆï¼\nåˆ°æ­¤ä¸ºæ­¢ï¼Œå·²ç»å¯ä»¥ä½¿ç”¨è‡ªå·±æ•°æ®ç©è€å„ç§Demoï¼Œå¿«ï¼ˆè‹¦ï¼‰ä¹ï¼ˆé€¼ï¼‰åœ°è¿›è¡Œç‚¼ä¸¹ä¹‹è·¯ã€‚é“è·¯é˜»ä¸”é•¿ï¼Œè¡Œåˆ™å°†è‡³ï¼Œä½†è¡Œå¥½äº‹è«é—®å‰ç¨‹ã€‚\n\nDemoæ¨¡å‹è¿˜å¯ä»¥ä¿®æ”¹Losså‡½æ•°ï¼Œä¼˜åŒ–å‡½æ•°å’Œæ¨¡å‹ç»“æ„ï¼Ÿ\né™¤äº†Torchinfoï¼Œæ˜¯å¦å¯ä»¥ä½¿ç”¨Tensorboardç­‰å¯è§†åŒ–å·¥å…·ç®¡ç†æ¨¡å‹æ•°æ®çš„å¯è§†åŒ–æ•°æ®å‘¢ï¼Ÿ\nDemoæ¨¡å‹ç¦»ç”Ÿäº§ä¸Šçº¿è¿˜æœ‰å¤šè¿œè·ç¦»ï¼Ÿå¦‚ä½•ä¸Šçº¿éƒ¨ç½²æ¨¡å‹å‘¢ï¼Ÿå¦‚ä½•å®ç°ä»Mysqlç­‰æ•°æ®åº“åˆ°çº¿ä¸Šæ¨¡å‹è°ƒç”¨å‘¢ï¼Ÿä»»ä½•çš„ä»£ç æ˜¯å¦éƒ½åº”è¯¥ä»¥èƒ½å¤Ÿç»ˆç«¯ä½¿ç”¨ä¸ºç›®çš„ï¼Ÿ\n\næ­£å¦‚ï¼Œäººå¾€å¾€ä¼šå¯¹æœªçŸ¥çš„äº‹æƒ…äº§ç”Ÿææƒ§ï¼Œå› ä¸ºç»“å±€æ˜¯æœªçŸ¥çš„ã€‚æ‰€ä»¥å½“ä¸€åˆ‡ä¸å†æœªçŸ¥çš„æ—¶å€™ï¼Œé‚£ä¹ˆæ˜¯ä¸æ˜¯å°±ä¸ä¼šäº§ç”Ÿææƒ§å‘¢ï¼Ÿ\n","categories":["æ·±åº¦å­¦ä¹ "],"tags":["Pytorch_Tutorial"]},{"title":"Pytorchç³»åˆ—è‡ªå­¦æ•™ç¨‹(3):æ·±åº¦å­¦ä¹ ä¹‹Mnistå›¾åƒåˆ†ç±»TorchServeéƒ¨ç½²","url":"/2022/06/06/Pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%95%99%E7%A8%8B-3-Mnist%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BBTorchServe%E9%83%A8%E7%BD%B2/","content":"ç®€ä»‹ç»è¿‡å‰ ä¸¤ç¯‡åšå®¢ å­¦ä¹ ï¼Œæˆ‘ä»¬å·²å¯ä½¿ç”¨CNNæ¨¡å‹å®ŒæˆMnistæ‰‹å†™æ•°å­—åˆ†ç±»æ¨¡å‹ï¼Œå¯¹äºç®—æ³•ä»æ•°æ®å¤„ç†ã€æ¨¡å‹æ„å»ºã€æ¨¡å‹è®­ç»ƒå’Œè¯„ä¼°é“¾è·¯æœ‰åˆæ­¥è®¤çŸ¥ã€‚ä½†å·¥ä¸šå¯èƒ½éœ€è¦éƒ¨ç½²ç¦»çº¿åœ¨çº¿æ¨¡å‹ç”¨äºæä¾›æ¨¡å‹æ¨ç†æœåŠ¡ï¼Œæ‰€è°“æ¨¡å‹æ¨ç†æœåŠ¡æ˜¯æŒ‡åœ¨ç³»ç»Ÿé…ç½®è®­ç»ƒå®Œæˆæœºå™¨å­¦ä¹ æ¨¡å‹ï¼Œä»¥ä¾¿å…¶å¯æ¥å—æ–°çš„è¾“å…¥å¹¶å°†æ¨ç†ç»“æœè¿”å›ç»™ç³»ç»Ÿã€‚\nå…¶æ¬¡ï¼Œè™½ç„¶å¾ˆå¤šå¤§å‚éƒ½ä¼šæœ‰å°è£…å¥½éƒ¨ç½²å¹³å°ä¾›ç®—æ³•äººå‘˜ä¾¿æ·é…ç½®ï¼Œä½†æ˜¯å­¦ä¹ ä¸­å¯¹äºå®Œæ•´çš„å·¥ç¨‹é“¾è·¯å¼€å‘å¯¹äºä¸ªäººèƒ½åŠ›å»ºè®¾ä¹Ÿæ˜¯éå¸¸é‡è¦çš„ï¼Œè€Œä¸æ˜¯ä»…ä»…ä½œä¸ºä¸€é¢—èºä¸é’‰ï¼Œå¦‚ä½•å®ç°ä»Demoæ¨¡å‹è½¬æ¢æˆçº¿ä¸Šæ¨¡å‹æ¨ç†æœåŠ¡éƒ¨ç½²ï¼Œå¯¹äºä¸ªäººçš„æ­£å‘åé¦ˆä¹Ÿæ˜¯éå¸¸æœ‰æ„ä¹‰çš„ã€‚\né‚£ä¹ˆé’ˆå¯¹ PyTorch è®­ç»ƒå¥½ Demo æ¨¡å‹ï¼Œå¦‚ä½•éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒç”¨äºæä¾›æ¨¡å‹æ¨ç†æœåŠ¡å‘¢ï¼Ÿéƒ¨ç½²å½¢å¼éå¸¸å¤šæ ·ï¼Œå…¶ä¸­ TorchServe æ˜¯ PyTorchå¼€æºé¡¹ç›® éƒ¨åˆ†ï¼Œæ˜¯AWSå’ŒFacebookåˆä½œå¼€å‘çš„ç”¨äºéƒ¨ç½²Pytorchçš„æ¨¡å‹ï¼Œå¯¹äºç®—æ³•å·¥ç¨‹å¸ˆæ˜¯ç›¸å½“å‹å¥½çš„ã€‚æœ¬ç« ä»‹ç»å¦‚ä½•ä½¿ç”¨TorchServeå®ŒæˆPyTorchæ¨¡å‹çš„éƒ¨ç½²å’Œè°ƒç”¨ã€‚\nTorchServeç®€ä»‹Torchserveæ˜¯PyTorchçš„é¦–é€‰æ¨¡å‹éƒ¨ç½²è§£å†³æ–¹æ¡ˆã€‚å®ƒå…è®¸ä¸ºæ¨¡å‹å…¬å¼€ä¸€ä¸ªå¯ä¾›ç›´æ¥è®¿é—®æˆ–è€…åº”ç”¨ç¨‹åºè®¿é—®çš„WebAPIï¼Œå€ŸåŠ©TorchServeï¼ŒPyTorchç”¨æˆ·å¯ä»¥æ›´å¿«åœ°å°†å…¶æ¨¡å‹åº”ç”¨äºç”Ÿäº§ï¼Œè€Œæ— éœ€ç¼–å†™è‡ªå®šä¹‰ä»£ç ï¼Œæ­¤å¤–ï¼ŒTorchServeå°†å·¥ç¨‹å¼€å‘å’Œç®—æ³•å¼€å‘è¿›è¡Œè§£è€¦ï¼Œç®—æ³•å·¥ç¨‹å¸ˆä¸»è¦å®Œæˆæ•°æ®Processå’Œæ¨¡å‹æ„å»ºè¿™ä¸€æ“…é•¿é¢†åŸŸï¼Œå…¶ä»–çš„å¤šæ¨¡å‹æœåŠ¡ã€A/Bæµ‹è¯•çš„ç‰ˆæœ¬æ§åˆ¶ã€ç›‘è§†æŒ‡æ ‡ä»¥åŠåº”ç”¨ç¨‹åºé›†æˆRESTfuléƒ½å·²å°è£…å¥½ã€‚\n\nTorchServe is a performant, flexible and easy to use tool for serving PyTorch eager mode and torschripted models.\n\nå®˜ç½‘ä»‹ç»å¯çœ‹å‡ºï¼šTorchServeæ˜¯ä¸€æ¬¾æ€§èƒ½å¥½ã€çµæ´»æ€§å¥½ã€æ˜“ä½¿ç”¨çš„å·¥å…·ï¼Œå…¶æ¬¡å¯éƒ¨ç½²æ¨¡å‹ç±»å‹æ˜¯Pytorchçš„Eageræ¨¡å¼å’ŒScriptæ¨¡å¼æ¨¡å‹ã€‚\nTorchServeæ¡†æ¶ä¸»è¦åˆ†ä¸ºå››ä¸ªéƒ¨åˆ†ï¼šFrontendæ˜¯TorchServeçš„è¯·æ±‚å’Œå“åº”çš„å¤„ç†éƒ¨åˆ†ï¼›WorkerProcess æŒ‡çš„æ˜¯ä¸€ç»„è¿è¡Œçš„æ¨¡å‹å®ä¾‹ï¼Œå¯ä»¥ç”±ç®¡ç†APIè®¾å®šè¿è¡Œçš„æ•°é‡ï¼›Model Storeæ˜¯æ¨¡å‹å­˜å‚¨åŠ è½½çš„åœ°æ–¹ï¼›Backendç”¨äºç®¡ç†Worker Processï¼Œå…·ä½“å¯å‚è€ƒä¸‹å›¾é‡Œã€‚\n\nç¯å¢ƒå®‰è£…æœ¬äººä½¿ç”¨ Windows11+WSL2+Ubuntu ç¯å¢ƒè¿›è¡Œéƒ¨ç½²ã€‚\nCondaé…ç½®å®˜ç½‘è¦æ±‚ï¼šPython Version &gt;= 3.8ï¼Œæœ¬æ–‡ä½¿ç”¨Condaç®¡ç†æ·±åº¦å­¦ä¹ ç¯å¢ƒï¼Œå…·ä½“ä½¿ç”¨å¯å‚è€ƒä¹‹å‰çš„åšæ–‡ï¼šæ·±åº¦å­¦ä¹ ç®¡ç†é…ç½®ã€‚\n\nå¯ä½¿ç”¨ä¸‹è¿°å‘½ä»¤åˆ›å»ºCondaçš„Pythonç¯å¢ƒï¼ˆpythonç‰ˆæœ¬ä¸º3.8ï¼Œç¯å¢ƒåä¸ºts_ENVï¼‰å’Œæ¿€æ´»æŒ‡å®šç¯å¢ƒ(ts_env)ã€‚\nconda create --name ts_env python=3.8conda activate ts_env\nTSæºç å®‰è£…å¯å‚è€ƒå®˜ç½‘TSå®‰è£…æ–‡æ¡£ã€‚\ngit clone https://github.com/pytorch/serve.gitcd serve./ts_scripts/setup_wsl_ubuntuexport PATH=$HOME/.local/bin:$PATHpython ./ts_scripts/install_from_src.pyecho &#x27;export PATH=$HOME/.local/bin:$PATH&#x27; &gt;&gt; ~/.bashrcsource ~/.bashrc\næ¨¡å‹æ‰“åŒ…TorchServe çš„ä¸€ä¸ªå…³é”®ç‰¹æ€§æ˜¯èƒ½å¤Ÿå°†æ‰€æœ‰æ¨¡å‹å·¥ä»¶æ‰“åŒ…åˆ°å•ä¸ªæ¨¡å‹å­˜æ¡£æ–‡ä»¶ä¸­ã€‚å®ƒæ˜¯ä¸€ä¸ªå•ç‹¬çš„å‘½ä»¤è¡Œç•Œé¢ (CLI)ï¼Œtorch-model-archiverï¼Œå¯ä»¥ä½¿ç”¨ state_dict è·å–æ¨¡å‹æ£€æŸ¥ç‚¹æˆ–æ¨¡å‹å®šä¹‰æ–‡ä»¶ï¼Œå¹¶å°†å®ƒä»¬æ‰“åŒ…æˆ .mar æ–‡ä»¶ã€‚ ç„¶åï¼Œä»»ä½•ä½¿ç”¨ TorchServe çš„äººéƒ½å¯ä»¥é‡æ–°åˆ†å‘å’Œæä¾›è¯¥æ–‡ä»¶ã€‚å®ƒåŒ…å«ä»¥ä¸‹æ¨¡å‹å·¥ä»¶ï¼šåœ¨ torchscript æˆ–æ¨¡å‹å®šä¹‰æ–‡ä»¶çš„æƒ…å†µä¸‹çš„æ¨¡å‹æ£€æŸ¥ç‚¹æ–‡ä»¶å’Œåœ¨æ€¥åˆ‡æ¨¡å¼çš„æƒ…å†µä¸‹çš„ state_dict æ–‡ä»¶ï¼Œä»¥åŠæœåŠ¡æ¨¡å‹å¯èƒ½éœ€è¦çš„å…¶ä»–å¯é€‰èµ„äº§ã€‚ CLI åˆ›å»ºä¸€ä¸ª .mar æ–‡ä»¶ï¼ŒTorchServe çš„æœåŠ¡å™¨ CLI ä½¿ç”¨è¯¥æ–‡ä»¶ä¸ºæ¨¡å‹æä¾›æœåŠ¡ã€‚\ntorch-model-archiver å‘½ä»¤æ¥æ‰“åŒ…æ¨¡å‹ï¼Œéœ€è¦æä¾›ä»¥ä¸‹ä¸‰ä¸ªæ–‡ä»¶ã€‚\nç¬¬ 1 æ­¥ï¼šåˆ›å»ºä¸€ä¸ªæ–°çš„æ¨¡å‹æ¶æ„æ–‡ä»¶ï¼Œå…¶ä¸­åŒ…å«ä» torch.nn.modules æ‰©å±•çš„æ¨¡å‹ç±»ã€‚åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬åˆ›å»ºäº†mnistæ¨¡å‹æ–‡ä»¶mnist_model.pyæ–‡ä»¶ã€‚\nimport torchfrom torch import nnimport torch.nn.functional as F# æ„å»ºç½‘ç»œclass MnistClassificationNet(nn.Module):    def __init__(self):        super().__init__()        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3)        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3)        self.max_pool2d = nn.MaxPool2d(kernel_size=2)        self.dropout = nn.Dropout2d(p=0.25)        # self.relu = nn.ReLU()        self.fc1 = nn.Linear(in_features=9216, out_features=128)        self.fc2 = nn.Linear(in_features=128, out_features=10)        self.log_softmax = nn.LogSoftmax(dim=1)    def forward(self, x):        x = self.conv1(x)        x = F.relu(x)        x = self.conv2(x)        x = F.relu(x)        x= self.max_pool2d(x)        x = self.dropout(x)        x = x.view(-1, 9216)        x = self.fc1(x)        x = F.relu(x)        x = self.fc2(x)        x= self.log_softmax(x)        return x\nç¬¬ 2 æ­¥ï¼šä½¿ç”¨ mnist_sd è®­ç»ƒ MNIST æ•°å­—è¯†åˆ«æ¨¡å‹å¹¶ä¿å­˜æ¨¡å‹çš„çŠ¶æ€å­—å…¸ã€‚\ntorch.save(model.state_dict(), &quot;./checkpoints/model_pth/mnist_sd.pt&quot;)\nç¬¬ 3 æ­¥ï¼šç¼–å†™è‡ªå®šä¹‰å¤„ç†ç¨‹åºä»¥åœ¨æ‚¨çš„æ¨¡å‹ä¸Šè¿è¡Œæ¨ç†ã€‚ åœ¨æ­¤ç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬æ·»åŠ äº†ä¸€ä¸ª mnist_handler.py æ–‡ä»¶ï¼Œå®ƒä½¿ç”¨ä¸Šè¿°æ¨¡å‹å¯¹è¾“å…¥ç°åº¦å›¾åƒè¿›è¡Œæ¨ç†å¹¶è¯†åˆ«å›¾åƒä¸­çš„æ•°å­—ã€‚\nfrom torchvision import transformsfrom ts.torch_handler.image_classifier import ImageClassifierfrom torch.profiler import ProfilerActivityclass MNISTDigitClassifier(ImageClassifier):    &quot;&quot;&quot;    MNISTDigitClassifier handler class. This handler extends class ImageClassifier from image_classifier.py, a    default handler. This handler takes an image and returns the number in that image.    Here method postprocess() has been overridden while others are reused from parent class.    &quot;&quot;&quot;    image_processing = transforms.Compose([        transforms.ToTensor()        # transforms.Normalize((0.1307,), (0.3081,))    ])    def __init__(self):        super(MNISTDigitClassifier, self).__init__()        self.profiler_args = &#123;            &quot;activities&quot; : [ProfilerActivity.CPU],            &quot;record_shapes&quot;: True,        &#125;    def postprocess(self, data):        &quot;&quot;&quot;The post process of MNIST converts the predicted output response to a label.        Args:            data (list): The predicted output from the Inference with probabilities is passed            to the post-process function        Returns:            list : A list of dictionaries with predictions and explanations is returned        &quot;&quot;&quot;        return data.argmax(1).tolist()        # return data.tolist()\nç¬¬ 4 æ­¥ï¼šä½¿ç”¨ torch-model-archiver ç¨‹åºåˆ›å»ºä¸€ä¸ª Torch æ¨¡å‹å­˜æ¡£ä»¥å­˜æ¡£ä¸Šè¿°æ–‡ä»¶ã€‚\n$ torch-model-archiver -husage: torch-model-archiver [-h] --model-name MODEL_NAME  --version MODEL_VERSION_NUMBER                      --model-file MODEL_FILE_PATH --serialized-file MODEL_SERIALIZED_PATH                      --handler HANDLER [--runtime &#123;python,python2,python3&#125;]                      [--export-path EXPORT_PATH] [-f] [--requirements-file]Model Archiver Tooloptional arguments:  -h, --help            show this help message and exit  --model-name MODEL_NAME                        Exported model name. Exported file will be named as                        model-name.mar and saved in current working directory                        if no --export-path is specified, else it will be                        saved under the export path  --serialized-file SERIALIZED_FILE                        Path to .pt or .pth file containing state_dict in                        case of eager mode or an executable ScriptModule                        in case of TorchScript.  --model-file MODEL_FILE                        Path to python file containing model architecture.                        This parameter is mandatory for eager mode models.                        The model architecture file must contain only one                        class definition extended from torch.nn.modules.  --handler HANDLER     TorchServe&#x27;s default handler name  or handler python                        file path to handle custom TorchServe inference logic.  --extra-files EXTRA_FILES                        Comma separated path to extra dependency files.  --runtime &#123;python,python2,python3&#125;                        The runtime specifies which language to run your                        inference code on. The default runtime is                        RuntimeType.PYTHON. At the present moment we support                        the following runtimes python, python2, python3  --export-path EXPORT_PATH                        Path where the exported .mar file will be saved. This                        is an optional parameter. If --export-path is not                        specified, the file will be saved in the current                        working directory.  --archive-format &#123;tgz,default&#125;                        The format in which the model artifacts are archived.                        &quot;tgz&quot;: This creates the model-archive in &lt;model-name&gt;.tar.gz format.                        If platform hosting requires model-artifacts to be in &quot;.tar.gz&quot;                        use this option.                        &quot;no-archive&quot;: This option creates an non-archived version of model artifacts                        at &quot;export-path/&#123;model-name&#125;&quot; location. As a result of this choice,                        MANIFEST file will be created at &quot;export-path/&#123;model-name&#125;&quot; location                        without archiving these model files                        &quot;default&quot;: This creates the model-archive in &lt;model-name&gt;.mar format.                        This is the default archiving format. Models archived in this format                        will be readily hostable on TorchServe.  -f, --force           When the -f or --force flag is specified, an existing                        .mar file with same name as that provided in --model-                        name in the path specified by --export-path will                        overwritten  -v, --version         Model&#x27;s version.  -r, --requirements-file                        Path to requirements.txt file containing a list of model specific python                        packages to be installed by TorchServe for seamless model serving.\ntorch-model-archiver --model-name mnist --version 1.0 --model-file mnist_model.py --serialized-file mnist_sd.pt --export-path ./model_store --handler mnist_handler.py -f\næ¨¡å‹éƒ¨ç½²$ torchserve --helpusage: torchserve [-h] [-v | --version]                          [--start]                          [--stop]                          [--ts-config TS_CONFIG]                          [--model-store MODEL_STORE]                          [--workflow-store WORKFLOW_STORE]                          [--models MODEL_PATH1 MODEL_NAME=MODEL_PATH2... [MODEL_PATH1 MODEL_NAME=MODEL_PATH2... ...]]                          [--log-config LOG_CONFIG]torchservemandatory arguments:  --model-store MODEL_STORE                        Model store location where models can be loaded  optional arguments:  -h, --help            show this help message and exit  -v, --version         Return TorchServe Version  --start               Start the model-server  --stop                Stop the model-server  --ts-config TS_CONFIG                        Configuration file for TorchServe  --models MODEL_PATH1 MODEL_NAME=MODEL_PATH2... [MODEL_PATH1 MODEL_NAME=MODEL_PATH2... ...]                        Models to be loaded using [model_name=]model_location                        format. Location can be a HTTP URL, a model archive                        file or directory contains model archive files in                        MODEL_STORE.  --log-config LOG_CONFIG                        Log4j configuration file for TorchServe  --ncs, --no-config-snapshots                                 Disable snapshot feature  --workflow-store WORKFLOW_STORE                        Workflow store location where workflow can be loaded. Defaults to model-store\nå¯åŠ¨torchserveæœåŠ¡torchserve --start --ncs --model-store model_store --models mnist.mar\næ¨¡å‹å¯åŠ¨æ—¥å¿—å¦‚ä¸‹æˆªå›¾ï¼š\n\næ¨ç†å¥åº·æ£€æŸ¥APIcurl http://localhost:8080/ping\nå¦‚æœserveræ­£å¸¸è¿è¡Œ, å“åº”ä¼šå¦‚æˆªå›¾æ‰€ç¤ºï¼š\n\næ¨ç†curl http://127.0.0.1:8080/predictions/mnist -T ./data/test.png\ntest.pngä¸ºæ•°å­—ä¸º0çš„å›¾ç‰‡ï¼Œé€šè¿‡ä¸Šè¿°çš„è°ƒç”¨æ¨ç†ï¼Œå¯ä»¥çœ‹å‡ºç»“æœæ˜¯èƒ½æ­£å¸¸è¿”å›çš„ï¼Œæ˜¯å¯ä»¥ä½œä¸ºä¸‹æ¸¸åº”ç”¨è°ƒç”¨ã€‚\n\nåœæ­¢torchserveæœåŠ¡torchserve --start\næ¢ç´¢å®Œæ•´ä»£ç å·²ä¸Šä¼ Githubï¼Œæœ‰éœ€è¦çš„å¯ä»¥è‡ªè¡Œä¸‹è½½ä»£ç ï¼Œå¦‚æœå¯¹ä½ æœ‰å¸®åŠ©ï¼Œè¯·Starï¼Œå“ˆå“ˆå“ˆå“ˆï¼\nåˆ°æ­¤ä¸ºæ­¢ï¼Œå·²ç»å¯ä»¥ä½¿ç”¨è‡ªå·±æ•°æ®ç©è€å„ç§Demoï¼Œå¿«ï¼ˆè‹¦ï¼‰ä¹ï¼ˆé€¼ï¼‰åœ°è¿›è¡Œç‚¼ä¸¹ä¹‹è·¯ã€‚é“è·¯é˜»ä¸”é•¿ï¼Œè¡Œåˆ™å°†è‡³ï¼Œä½†è¡Œå¥½äº‹è«é—®å‰ç¨‹ã€‚\n\né™¤äº†ä½¿ç”¨TorchServeéƒ¨ç½²æ¨¡å‹ï¼Œè¿˜æœ‰å…¶ä»–çš„è§£å†³æ–¹æ¡ˆå—ï¼Ÿ\né™¤äº†ä½¿ç”¨æä¾›è¿™ç§Web APIçš„å½¢å¼ï¼Œæ˜¯å¦å¯ä»¥æ„å»ºä¸€ä¸ªGUIçš„å½¢å¼æä¾›å‘¢ï¼Ÿä¾‹å¦‚ PYQT5 ï¼Ÿè¿™é‡Œæ”¾ä¸€å¼ PYQT5çš„å›¾ï¼Œåé¢ä¼šå¡«å‘ã€‚\n\n\næ­£å¦‚ï¼Œäººå¾€å¾€ä¼šå¯¹æœªçŸ¥çš„äº‹æƒ…äº§ç”Ÿææƒ§ï¼Œå› ä¸ºç»“å±€æ˜¯æœªçŸ¥çš„ã€‚æ‰€ä»¥å½“ä¸€åˆ‡ä¸å†æœªçŸ¥çš„æ—¶å€™ï¼Œé‚£ä¹ˆæ˜¯ä¸æ˜¯å°±ä¸ä¼šäº§ç”Ÿææƒ§å‘¢ï¼Ÿ\nå‚è€ƒMore info: Chengluï¼šå¦‚ä½•éƒ¨ç½²PyTorchæ¨¡å‹More info: TorchServeMore info: TorchServe_Mnist ExampleMore info: éšä¾¿å†™ç‚¹ç¬”è®°More info: PyTorch Eager mode and Script modeMore info: Self-host your ğŸ¤—HuggingFace Transformer NER model with Torchserve + StreamlitMore info: TorchServeæ­å»ºcodeBERTåˆ†ç±»æ¨¡å‹æœåŠ¡More info: torchserveræ¨¡å‹æœ¬åœ°éƒ¨ç½²å’Œdockeréƒ¨ç½²\n","tags":["Pytorch_Tutorial"]},{"title":"Pytorchç³»åˆ—è‡ªå­¦æ•™ç¨‹(4):æ·±åº¦å­¦ä¹ ä¹‹åºåˆ—æ¨¡å‹","url":"/2022/06/12/Pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%95%99%E7%A8%8B-4-%E5%BA%8F%E5%88%97%E6%A8%A1%E5%9E%8B/","content":"åºåˆ—æ¨¡å‹ä»‹ç»å¾ªç¯ç¥ç»ç½‘ç»œï¼ˆRecurrent Neural Networkï¼ŒRNNï¼‰æ˜¯ä¸€ç§ç”¨äºå¤„ç†åºåˆ—æ•°æ®çš„ç¥ç»ç½‘ç»œã€‚ç›¸æ¯”ä¸€èˆ¬çš„ç¥ç»ç½‘ç»œæ¥è¯´ï¼Œä»–èƒ½å¤Ÿå¤„ç†åºåˆ—å˜åŒ–çš„æ•°æ®ã€‚æ¯”å¦‚æŸä¸ªå•è¯çš„æ„æ€ä¼šå› ä¸ºä¸Šæ–‡æåˆ°çš„å†…å®¹ä¸åŒè€Œæœ‰ä¸åŒçš„å«ä¹‰ï¼ŒRNNå°±èƒ½å¤Ÿå¾ˆå¥½åœ°è§£å†³è¿™ç±»é—®é¢˜ã€‚RNNä¹Ÿå¯ä»¥å †å åœ¨ä¸€èµ·ã€‚éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œå †ä¸­çš„æ¯ä¸ªRNNéƒ½æœ‰è‡ªå·±çš„æƒé‡çŸ©é˜µã€‚å› æ­¤ï¼Œæƒé‡çŸ©é˜µåœ¨æ°´å¹³è½´ï¼ˆæ—¶é—´è½´ï¼‰ä¸Šå…±äº«ï¼Œè€Œä¸æ˜¯åœ¨å‚ç›´è½´ï¼ˆRNNçš„æ•°é‡ï¼‰ä¸Šå…±äº«ã€‚\n\nå› RNNæ¨¡å‹è®­ç»ƒé‡‡ç”¨BPTTç®—æ³•(BackPropagation Through Time)ï¼Œå¯¼è‡´RNNæœ‰ä¸€ä¸ªä¸»è¦çš„ç¼ºç‚¹ï¼Œå³æ‰€è°“çš„æ¢¯åº¦æ¶ˆå¤±å’Œæ¢¯åº¦çˆ†ç‚¸ï¼Œè€Œæ¢¯åº¦çˆ†ç‚¸é—®é¢˜å¯ä»¥é€šè¿‡æ¢¯åº¦è£å‰ªï¼Œå»æŠ‘åˆ¶ï¼Œæ¢¯åº¦æ¶ˆå¤±çš„é—®é¢˜æ˜¯éšç€åå‘ä¼ æ’­ï¼Œæ¢¯åº¦è¶Šæ¥è¶Šå°ï¼Œåœ¨è¿™äº›ç½‘ç»œä¸­ï¼Œéšç€æ—¶é—´æ­¥é•¿çš„å¢åŠ ï¼Œåå‘ä¼ æ’­ä½¿æ¢¯åº¦å˜å¾—è¶Šæ¥è¶Šå°ï¼Œå¯¼è‡´æ¢¯åº¦æ¶ˆå¤±ã€‚è¿›è€Œå¯¼è‡´RNNé•¿æœŸä¾èµ–é—®é¢˜ã€‚æ³¨æ„ï¼Œè£å‰ªä»…é™åˆ¶æ¢¯åº¦çš„å¤§å°ï¼Œè€Œä¸é™åˆ¶å…¶æ–¹å‘ã€‚æ‰€ä»¥ï¼Œå­¦ä¹ ä»ç„¶æœç€æ­£ç¡®çš„æ–¹å‘å‰è¿›ã€‚\nhttps://www.zhihu.com/question/279046805/answer/1153623199\n","tags":["Pytorch_Tutorial"]},{"title":"Windowsç³»ç»Ÿä½¿ç”¨Condaé…ç½®æ·±åº¦å­¦ä¹ ç¯å¢ƒ","url":"/2022/05/15/Windows%E7%B3%BB%E7%BB%9F%E4%BD%BF%E7%94%A8Conda%E9%85%8D%E7%BD%AE%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83/","content":"Condaç¯å¢ƒç®¡ç†Condaæ˜¯ä¸€ä¸ªå¼€æºè½¯ä»¶åŒ…ç®¡ç†ç³»ç»Ÿå’Œç¯å¢ƒç®¡ç†ç³»ç»Ÿï¼Œå¯ä»¥ç®¡ç†ä¸åŒPythonç‰ˆæœ¬ç¯å¢ƒï¼Œä¸åŒçš„ç¯å¢ƒä¹‹é—´æ˜¯äº’ç›¸éš”ç¦»ï¼Œäº’ä¸å½±å“çš„ã€‚\næŸ¥çœ‹ç¯å¢ƒ# æŸ¥çœ‹å½“å‰ç¯å¢ƒconda info --env\nå…‹éš†ç¯å¢ƒ# å‡è®¾å·²æœ‰ç¯å¢ƒåä¸ºAï¼Œéœ€è¦ç”Ÿæˆçš„ç¯å¢ƒåä¸ºBï¼šconda create -n B --clone A# å¦‚æœç‰¹æ®Šç¯å¢ƒä¸ºBaseï¼Œéœ€è¦é‡‡ç”¨ä»¥ä¸‹æ–¹å¼conda update condaconda create -n &lt;my_env&gt; --clone rootconda create -n torch_env --clone rootconda install pytorch=0.4.0 cuda90 -c pytorch# ç”¨äºå¤åˆ¶ç¯å¢ƒåˆ°æ–°çš„æœºå™¨conda list --explicit &gt; spec-file.txtconda create --name &lt;my_env&gt; --file spec-file.txt\nåˆ›å»ºç¯å¢ƒ# åˆ›å»ºä¸€ä¸ªç¯å¢ƒåä¸ºpy34ï¼ŒæŒ‡å®šPythonç‰ˆæœ¬æ˜¯3.4 #ï¼ˆä¸ç”¨ç®¡æ˜¯3.4.xï¼Œcondaä¼šä¸ºæˆ‘ä»¬è‡ªåŠ¨å¯»æ‰¾3.4.xä¸­çš„æœ€æ–°ç‰ˆæœ¬ï¼‰ conda create --name py34 python=3.4 # é€šè¿‡åˆ›å»ºç¯å¢ƒï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä¸åŒç‰ˆæœ¬çš„Python conda create --name py27 python=2.7\næ¿€æ´»ç¯å¢ƒ# åœ¨windowsç¯å¢ƒä¸‹ä½¿ç”¨activateæ¿€æ´» activate py34# åœ¨Linux &amp; Macä¸­ä½¿ç”¨source activateæ¿€æ´» source activate py34 \né€€å‡ºç¯å¢ƒ# åœ¨windowsç¯å¢ƒä¸‹ä½¿ç”¨deactivate &lt;my_env&gt;# åœ¨Linux &amp; Macä¸­ä½¿ç”¨source deactivate &lt;my_env&gt;\nåˆ é™¤ç¯å¢ƒ# å¦‚æœä½ ä¸æƒ³è¦è¿™ä¸ªåä¸ºpy34çš„ç¯å¢ƒï¼Œå¯ä»¥é€šè¿‡ä»¥ä¸‹å‘½ä»¤åˆ é™¤è¿™ä¸ªç¯å¢ƒã€‚ conda remove -n py34 --all # å¯ä»¥é€šè¿‡ä»¥ä¸‹å‘½ä»¤æŸ¥çœ‹å·²æœ‰çš„ç¯å¢ƒåˆ—è¡¨ï¼Œç°åœ¨py34å·²ç»ä¸åœ¨è¿™ä¸ªåˆ—è¡¨é‡Œã€‚ conda info -e\né…ç½®é•œåƒ# æ˜¾ç¤ºç›®å‰çš„channels conda config --show channels # åˆ‡æ¢é»˜è®¤é•œåƒæº conda config --remove-key channels# åˆ é™¤æŒ‡å®šchannel conda config --remove channels_URL # Windows ç”¨æˆ·æ— æ³•ç›´æ¥åˆ›å»ºåä¸º .condarc çš„æ–‡ä»¶ï¼Œä½¿ç”¨ä»¥ä¸‹å‘½ä»¤ C:\\Users\\ç”¨æˆ·å\\.condarcconda config --set show_channel_urls yes# ä¸­ç§‘å¤§é•œåƒæº conda config --add channels https://mirrors.ustc.edu.cn/anaconda/pkgs/main/ conda config --add channels https://mirrors.ustc.edu.cn/anaconda/pkgs/free/conda config --add channels https://mirrors.ustc.edu.cn/anaconda/cloud/conda-forge/ conda config --add channels https://mirrors.ustc.edu.cn/anaconda/cloud/msys2/ conda config --add channels https://mirrors.ustc.edu.cn/anaconda/cloud/bioconda/ conda config --add channels https://mirrors.ustc.edu.cn/anaconda/cloud/menpo/ conda config --add channels https://mirrors.ustc.edu.cn/anaconda/cloud/  # åŒ—äº¬å¤–å›½è¯­å¤§å­¦æº conda config --add channels https://mirrors.bfsu.edu.cn/anaconda/pkgs/main conda config --add channels https://mirrors.bfsu.edu.cn/anaconda/pkgs/free conda config --add channels https://mirrors.bfsu.edu.cn/anaconda/pkgs/r conda config --add channels https://mirrors.bfsu.edu.cn/anaconda/pkgs/pro conda config --add channels https://mirrors.bfsu.edu.cn/anaconda/pkgs/msys2# æ¸…åæº conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/mainconda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/r conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/pro conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/msys2 \nTensorflowç¯å¢ƒå®‰è£…æŸ¥çœ‹Tensorflowç‰ˆæœ¬å’Œå®‰è£…æŒ‡å®šç‰ˆæœ¬ã€‚\n# æŸ¥è¯¢tensorflow-gpuçš„ç‰ˆæœ¬conda search tensorflow-gpu# æŒ‡å®šç‰ˆæœ¬è¿›è¡Œå®‰è£…conda install tensorflow-gpu==1.13.1\n\nå®‰è£…è¿‡ç¨‹ä¸­ä¼šå®‰è£…cudatoolkit-10.0.130å’Œcudnn-7.6.5ã€‚\n\næ‰§è¡Œä¸‹è¿°å‘½ä»¤æŸ¥çœ‹tfç‰ˆæœ¬å’ŒGPUæ˜¯å¦ç”Ÿæ•ˆã€‚\næŸ¥çœ‹æ˜¯å¦å®‰è£…æˆåŠŸimport tensorflow as tf# æ‰“å°Tensorflowç‰ˆæœ¬print(tf.__version__)# æ‰“å°æ˜¯å¦æ”¯æŒGPUprint(tf.test.is_gpu_available())\næ ¹æ®å›¾ç‰‡æ‰“å°ç»“æœï¼ŒæˆåŠŸå®‰è£…tf 1.13.1 ç‰ˆæœ¬ï¼ŒåŒæ—¶GPUå®‰è£…ç”Ÿæ•ˆã€‚\n\nPytorchç¯å¢ƒå®‰è£…æ‰§è¡Œä¸‹è¿°å‘½ä»¤å®‰è£…Pytorchã€‚\nconda install pytorch==1.7.0 torchvision==0.8.0 torchaudio==0.7.0 cudatoolkit=10.1 -c pytorch\næ‰§è¡Œä¸‹è¿°å‘½ä»¤æŸ¥çœ‹torchç‰ˆæœ¬å’ŒGPUæ˜¯å¦ç”Ÿæ•ˆã€‚\nimport torchprint(torch.__version__)print(torch.cuda.is_available())\næ ¹æ®å›¾ç‰‡æ‰“å°ç»“æœï¼ŒæˆåŠŸå®‰è£…Pytorch 1.7.0 ç‰ˆæœ¬ï¼ŒåŒæ—¶GPUå®‰è£…ç”Ÿæ•ˆã€‚\n\nå‚è€ƒ\nMore info: é˜¿å°”å‘goï¼šcondaå¸¸ç”¨å‘½ä»¤\n\nMore info: å–èŒå“¥ï¼šcondaçš„å®‰è£…ä¸ä½¿ç”¨\n\nMore info: æ— èŠå°±çœ‹ä¹¦ï¼šTensorflow-gpu1.13.1 å’Œ Tensorflow-gpu2.0.0å…±å­˜ä¹‹å®‰è£…æ•™ç¨‹\n\n\n","tags":["Conda"]},{"title":"snippets","url":"/2022/05/08/snippets/","content":"æœ¬åšå®¢çš„ç›®çš„ä¸»è¦æ˜¯ä¸ºäº†æ”¶é›†ä¸€äº›å¸¸ç”¨ä»£ç ï¼Œæˆ–è€…ä¸€äº›æœ‰æ„æ€çš„ä»£ç ï¼Œæ–¹ä¾¿åç»­çš„å·¥ä½œå­¦ä¹ ä½¿ç”¨ã€‚\nSklearnçš„datasetè½¬ä¸ºdataframeimport pandas as pdfrom sklearn import datasetsdef sklearn_to_df(sklearn_dataset):    df = pd.DataFrame(sklearn_dataset.data, columns=sklearn_dataset.feature_names)    df[&#x27;TARGET&#x27;] = pd.Series(sklearn_dataset.target)    return dfdf_boston = sklearn_to_df(datasets.load_boston())print(df_boston.head())\npymysqlè¯»å–mysqlæ•°æ®è½¬åŒ–ä¸ºdataframeimport pymysqlimport pandas as pddef load_data_frame_from_mysql():    conn = pymysql.connect(host=&quot;127.0.0.1&quot;,                           port=3307,                           user=&quot;utest&quot;,                           password=&quot;123456xyq&quot;,                           db=&quot;sakila&quot;,                           charset=&quot;utf8&quot;)    sql = &quot;SELECT * FROM sakila.payment&quot;    data_frame = pd.read_sql(sql, conn)    return data_framepdata = load_data_frame_from_mysql()print(pdata.head())\nImageå¤„ç†ä»£ç # -*-coding: utf-8 -*-&quot;&quot;&quot;    @Project: IntelligentManufacture    @File   : image_processing.py    @Author : panjq    @E-mail : pan_jinquan@163.com    @Date   : 2019-02-14 15:34:50&quot;&quot;&quot; import osimport globimport cv2import numpy as npimport matplotlib.pyplot as plt def show_image(title, image):    &#x27;&#x27;&#x27;    è°ƒç”¨matplotlibæ˜¾ç¤ºRGBå›¾ç‰‡    :param title: å›¾åƒæ ‡é¢˜    :param image: å›¾åƒçš„æ•°æ®    :return:    &#x27;&#x27;&#x27;    # plt.figure(&quot;show_image&quot;)    # print(image.dtype)    plt.imshow(image)    plt.axis(&#x27;on&#x27;)  # å…³æ‰åæ ‡è½´ä¸º off    plt.title(title)  # å›¾åƒé¢˜ç›®    plt.show() def cv_show_image(title, image):    &#x27;&#x27;&#x27;    è°ƒç”¨OpenCVæ˜¾ç¤ºRGBå›¾ç‰‡    :param title: å›¾åƒæ ‡é¢˜    :param image: è¾“å…¥RGBå›¾åƒ    :return:    &#x27;&#x27;&#x27;    channels=image.shape[-1]    if channels==3:        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)  # å°†BGRè½¬ä¸ºRGB    cv2.imshow(title,image)    cv2.waitKey(0) def read_image(filename, resize_height=None, resize_width=None, normalization=False):    &#x27;&#x27;&#x27;    è¯»å–å›¾ç‰‡æ•°æ®,é»˜è®¤è¿”å›çš„æ˜¯uint8,[0,255]    :param filename:    :param resize_height:    :param resize_width:    :param normalization:æ˜¯å¦å½’ä¸€åŒ–åˆ°[0.,1.0]    :return: è¿”å›çš„RGBå›¾ç‰‡æ•°æ®    &#x27;&#x27;&#x27;     bgr_image = cv2.imread(filename)    # bgr_image = cv2.imread(filename,cv2.IMREAD_IGNORE_ORIENTATION|cv2.IMREAD_COLOR)    if bgr_image is None:        print(&quot;Warning:ä¸å­˜åœ¨:&#123;&#125;&quot;, filename)        return None    if len(bgr_image.shape) == 2:  # è‹¥æ˜¯ç°åº¦å›¾åˆ™è½¬ä¸ºä¸‰é€šé“        print(&quot;Warning:gray image&quot;, filename)        bgr_image = cv2.cvtColor(bgr_image, cv2.COLOR_GRAY2BGR)     rgb_image = cv2.cvtColor(bgr_image, cv2.COLOR_BGR2RGB)  # å°†BGRè½¬ä¸ºRGB    # show_image(filename,rgb_image)    # rgb_image=Image.open(filename)    rgb_image = resize_image(rgb_image,resize_height,resize_width)    rgb_image = np.asanyarray(rgb_image)    if normalization:        # ä¸èƒ½å†™æˆ:rgb_image=rgb_image/255        rgb_image = rgb_image / 255.0    # show_image(&quot;src resize image&quot;,image)    return rgb_image def fast_read_image_roi(filename, orig_rect, ImreadModes=cv2.IMREAD_COLOR, normalization=False):    &#x27;&#x27;&#x27;    å¿«é€Ÿè¯»å–å›¾ç‰‡çš„æ–¹æ³•    :param filename: å›¾ç‰‡è·¯å¾„    :param orig_rect:åŸå§‹å›¾ç‰‡çš„æ„Ÿå…´è¶£åŒºåŸŸrect    :param ImreadModes: IMREAD_UNCHANGED                        IMREAD_GRAYSCALE                        IMREAD_COLOR                        IMREAD_ANYDEPTH                        IMREAD_ANYCOLOR                        IMREAD_LOAD_GDAL                        IMREAD_REDUCED_GRAYSCALE_2                        IMREAD_REDUCED_COLOR_2                        IMREAD_REDUCED_GRAYSCALE_4                        IMREAD_REDUCED_COLOR_4                        IMREAD_REDUCED_GRAYSCALE_8                        IMREAD_REDUCED_COLOR_8                        IMREAD_IGNORE_ORIENTATION    :param normalization: æ˜¯å¦å½’ä¸€åŒ–    :return: è¿”å›æ„Ÿå…´è¶£åŒºåŸŸROI    &#x27;&#x27;&#x27;    # å½“é‡‡ç”¨IMREAD_REDUCEDæ¨¡å¼æ—¶ï¼Œå¯¹åº”rectä¹Ÿéœ€è¦ç¼©æ”¾    scale=1    if ImreadModes == cv2.IMREAD_REDUCED_COLOR_2 or ImreadModes == cv2.IMREAD_REDUCED_COLOR_2:        scale=1/2    elif ImreadModes == cv2.IMREAD_REDUCED_GRAYSCALE_4 or ImreadModes == cv2.IMREAD_REDUCED_COLOR_4:        scale=1/4    elif ImreadModes == cv2.IMREAD_REDUCED_GRAYSCALE_8 or ImreadModes == cv2.IMREAD_REDUCED_COLOR_8:        scale=1/8    rect = np.array(orig_rect)*scale    rect = rect.astype(int).tolist()    bgr_image = cv2.imread(filename,flags=ImreadModes)     if bgr_image is None:        print(&quot;Warning:ä¸å­˜åœ¨:&#123;&#125;&quot;, filename)        return None    if len(bgr_image.shape) == 3:  #        rgb_image = cv2.cvtColor(bgr_image, cv2.COLOR_BGR2RGB)  # å°†BGRè½¬ä¸ºRGB    else:        rgb_image=bgr_image #è‹¥æ˜¯ç°åº¦å›¾    rgb_image = np.asanyarray(rgb_image)    if normalization:        # ä¸èƒ½å†™æˆ:rgb_image=rgb_image/255        rgb_image = rgb_image / 255.0    roi_image=get_rect_image(rgb_image , rect)    # show_image_rect(&quot;src resize image&quot;,rgb_image,rect)    # cv_show_image(&quot;reROI&quot;,roi_image)    return roi_image def resize_image(image,resize_height, resize_width):    &#x27;&#x27;&#x27;    :param image:    :param resize_height:    :param resize_width:    :return:    &#x27;&#x27;&#x27;    image_shape=np.shape(image)    height=image_shape[0]    width=image_shape[1]    if (resize_height is None) and (resize_width is None):#é”™è¯¯å†™æ³•ï¼šresize_height and resize_width is None        return image    if resize_height is None:        resize_height=int(height*resize_width/width)    elif resize_width is None:        resize_width=int(width*resize_height/height)    image = cv2.resize(image, dsize=(resize_width, resize_height))    return imagedef scale_image(image,scale):    &#x27;&#x27;&#x27;    :param image:    :param scale: (scale_w,scale_h)    :return:    &#x27;&#x27;&#x27;    image = cv2.resize(image,dsize=None, fx=scale[0],fy=scale[1])    return image  def get_rect_image(image,rect):    &#x27;&#x27;&#x27;    :param image:    :param rect: [x,y,w,h]    :return:    &#x27;&#x27;&#x27;    x, y, w, h=rect    cut_img = image[y:(y+ h),x:(x+w)]    return cut_imgdef scale_rect(orig_rect,orig_shape,dest_shape):    &#x27;&#x27;&#x27;    å¯¹å›¾åƒè¿›è¡Œç¼©æ”¾æ—¶ï¼Œå¯¹åº”çš„rectangleä¹Ÿè¦è¿›è¡Œç¼©æ”¾    :param orig_rect: åŸå§‹å›¾åƒçš„rect=[x,y,w,h]    :param orig_shape: åŸå§‹å›¾åƒçš„ç»´åº¦shape=[h,w]    :param dest_shape: ç¼©æ”¾åå›¾åƒçš„ç»´åº¦shape=[h,w]    :return: ç»è¿‡ç¼©æ”¾åçš„rectangle    &#x27;&#x27;&#x27;    new_x=int(orig_rect[0]*dest_shape[1]/orig_shape[1])    new_y=int(orig_rect[1]*dest_shape[0]/orig_shape[0])    new_w=int(orig_rect[2]*dest_shape[1]/orig_shape[1])    new_h=int(orig_rect[3]*dest_shape[0]/orig_shape[0])    dest_rect=[new_x,new_y,new_w,new_h]    return dest_rect def show_image_rect(win_name,image,rect):    &#x27;&#x27;&#x27;    :param win_name:    :param image:    :param rect:    :return:    &#x27;&#x27;&#x27;    x, y, w, h=rect    point1=(x,y)    point2=(x+w,y+h)    cv2.rectangle(image, point1, point2, (0, 0, 255), thickness=2)    cv_show_image(win_name, image) def rgb_to_gray(image):    image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)    return image def save_image(image_path, rgb_image,toUINT8=True):    if toUINT8:        rgb_image = np.asanyarray(rgb_image * 255, dtype=np.uint8)    if len(rgb_image.shape) == 2:  # è‹¥æ˜¯ç°åº¦å›¾åˆ™è½¬ä¸ºä¸‰é€šé“        bgr_image = cv2.cvtColor(rgb_image, cv2.COLOR_GRAY2BGR)    else:        bgr_image = cv2.cvtColor(rgb_image, cv2.COLOR_RGB2BGR)    cv2.imwrite(image_path, bgr_image) def combime_save_image(orig_image, dest_image, out_dir,name,prefix):    &#x27;&#x27;&#x27;    å‘½åæ ‡å‡†ï¼šout_dir/name_prefix.jpg    :param orig_image:    :param dest_image:    :param image_path:    :param out_dir:    :param prefix:    :return:    &#x27;&#x27;&#x27;    dest_path = os.path.join(out_dir, name + &quot;_&quot;+prefix+&quot;.jpg&quot;)    save_image(dest_path, dest_image)     dest_image = np.hstack((orig_image, dest_image))    save_image(os.path.join(out_dir, &quot;&#123;&#125;_src_&#123;&#125;.jpg&quot;.format(name,prefix)), dest_image)\napt-getå¸è½½è½¯ä»¶# åˆ é™¤è½¯ä»¶åŠå…¶é…ç½®æ–‡ä»¶apt-get --purge remove openjdk-11-jdk# åˆ é™¤æ²¡ç”¨çš„ä¾èµ–åŒ…sudo apt-get autoremove openjdk-11-jdk# æ­¤æ—¶dpkgçš„åˆ—è¡¨ä¸­æœ‰â€œrcâ€çŠ¶æ€çš„è½¯ä»¶åŒ…ï¼Œå¯ä»¥æ‰§è¡Œå¦‚ä¸‹å‘½ä»¤åšæœ€åæ¸…ç†ï¼šdpkg -l |grep ^rc|awk &#x27;&#123;print $2&#125;&#x27; |sudo xargs dpkg -P\n","categories":["Snippet"],"tags":["Snippet","Python"]},{"title":"ä½¿ç”¨GithubPagesæ­å»ºä¸ªäººé™æ€åšå®¢","url":"/2022/05/01/%E4%BD%BF%E7%94%A8GithubPages%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E9%9D%99%E6%80%81%E5%8D%9A%E5%AE%A2/","content":"åŸç†GitHub Pages æ˜¯ä½¿ç”¨ GitHub å­˜å‚¨ä»“åº“æ‰˜ç®¡é™æ€ç½‘ç«™ï¼Œä½¿ç”¨ YAML å’Œ Markdown ç­‰æ ‡å‡†æŠ€æœ¯ï¼Œä»»ä½•äººéƒ½å¯ä»¥åœ¨å‡ åˆ†é’Ÿå†…ç”Ÿæˆå’Œç»´æŠ¤ç½‘ç«™ï¼Œä½†å®ƒä¸ä»…ä»…æ˜¯é™æ€æ–‡ä»¶çš„é›†åˆã€‚é€šè¿‡åˆ©ç”¨ Jekyll å’Œ Liquid ç­‰ç½‘ç«™ç”ŸæˆæŠ€æœ¯ï¼Œå¼€å‘äººå‘˜å¯å®šä¹‰å®Œæ•´é™æ€ç½‘ç«™çš„åŠ¨æ€æ¨¡æ¿ã€‚æ¯æ¬¡å°†æ›´æ”¹æäº¤åˆ°ä¸ç½‘ç«™å…³è”çš„æºä»£ç åˆ†æ”¯æ—¶ï¼Œéƒ½ä¼šä½¿ç”¨æºä»£ç åˆ†æ”¯çš„æœ€æ–°ä»£ç é…ç½®é‡æ–°ç”Ÿæˆé™æ€ç½‘é¡µï¼ŒGithub è‡ªåŠ¨å°†å…¶å‘å¸ƒåˆ°ç›®æ ‡ URLã€‚æ¬¢è¿å…³æ³¨ï¼šæˆ‘çš„åšå®¢ã€‚\nç¯å¢ƒé…ç½®æ“ä½œç³»ç»Ÿï¼šWindows11 -&gt; WSL2 -&gt; Ubuntu 22.04 LTSNode.js: v16.15.0Npm: 8.5.5\næ“ä½œéƒ¨ç½²å®‰è£…NVMåœ¨å®‰è£…nvmä¹‹å‰ç®€å•ä»‹ç»ä¸‹nvmï¼Œnodejså’Œnpmä¹‹é—´çš„å…³ç³»ã€‚\n\nnvmï¼šnodejs çš„ç‰ˆæœ¬ç®¡ç†å·¥å…·ã€‚\nnodejsï¼šé¡¹ç›®å¼€å‘æ‰€éœ€è¦çš„ä»£ç åº“ã€‚\nnpmï¼šnodejs åŒ…ç®¡ç†å·¥å…·ï¼Œnpm ç®¡ç†nodejsä¸­çš„ç¬¬ä¸‰æ–¹æ’ä»¶ã€‚\n\nå‚è€ƒ NPM-GITHUBï¼Œä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å®‰è£…nvmã€‚\nwget -qO- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.1/install.sh | bash\nå®‰è£…è¿‡ç¨‹Infoæˆªå›¾å¦‚ä¸‹ï¼š\n\nåˆ¤æ–­nvmå®‰è£…æ˜¯å¦æˆåŠŸ,å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤æŸ¥çœ‹nvmçš„ç‰ˆæœ¬ä¿¡æ¯ã€‚\nnvm -v\n\nå®‰è£…NODEJSä½¿ç”¨ nvm install å‘½ä»¤å¯ä»¥å®‰è£…æŒ‡å®šç‰ˆæœ¬çš„NodeJsï¼Œæœ¬æ¬¡å®‰è£…v16ç‰ˆæœ¬ï¼Œæ‰§è¡Œä»¥ä¸‹å‘½ä»¤ã€‚\nnvm install 16\né€šè¿‡ä¸‹è¿°å‘½ä»¤æŸ¥çœ‹nodeå’Œnpmçš„ç‰ˆæœ¬ã€‚\nnode -vnpm -v\nå¯æŸ¥çœ‹åˆ°Nodeå’Œnpmçš„ç‰ˆæœ¬ã€‚\n\nå®‰è£…Hexoå’Œé…ç½®å®‰è£…Hexoå‘½ä»¤è¡ŒHexoæ˜¯ä¸€ä¸ªå¿«é€Ÿã€ç®€æ´ä¸”é«˜æ•ˆçš„åšå®¢æ¡†æ¶ï¼Œå®˜æ–¹æä¾›ä¸€ä¸ªå‘½ä»¤è¡Œå·¥å…·ï¼Œç”¨äºå¿«é€Ÿåˆ›å»ºé¡¹ç›®ã€é¡µé¢ã€ç¼–è¯‘ã€éƒ¨ç½²Hexoåšå®¢ï¼Œå®‰è£…å‘½ä»¤è¡Œå·¥å…·ã€‚\nnpm install -g hexo-cli\nåˆå§‹åŒ–æœ¬åœ°è¿è¡Œæ¥ä¸‹æ¥æˆ‘ä»¬ä½¿ç”¨ Hexo å‘½ä»¤è¡Œåˆ›å»ºä¸€ä¸ªé¡¹ç›®ï¼Œå¹¶å°†å…¶åœ¨æœ¬åœ°è·‘èµ·æ¥ï¼Œæ•´ä½“è·‘é€šçœ‹çœ‹ã€‚\né¦–å…ˆä½¿ç”¨å¦‚ä¸‹å‘½ä»¤åˆ›å»ºé¡¹ç›®ï¼šhexo init {blog_name}ï¼Œè¿™é‡Œçš„ blog_name å°±æ˜¯åšå®¢åï¼Œæˆ‘è¿™é‡Œè¦åˆ›å»º hexo_blog çš„åšå®¢ï¼Œæˆ‘å°±æŠŠé¡¹ç›®å–åä¸º hexo_blog ï¼Œå‘½ä»¤å¦‚ä¸‹ï¼šhexo init hexo_blogã€‚\nhexo init &#123;blog_name&#125;cd &#123;blog_name&#125;npm installhexo server\nhexo_blog æ–‡ä»¶å¤¹ä¸‹å°±ä¼šå‡ºç° Hexo çš„åˆå§‹åŒ–æ–‡ä»¶ï¼ŒåŒ…æ‹¬ themesã€scaffoldsã€source ç­‰æ–‡ä»¶å¤¹ã€‚\n\næ¥ä¸‹æ¥æˆ‘ä»¬é¦–å…ˆè¿›å…¥æ–°ç”Ÿæˆçš„æ–‡ä»¶å¤¹é‡Œé¢ï¼Œç„¶åè°ƒç”¨ Hexo çš„ generate å‘½ä»¤ï¼Œå°† Hexo ç¼–è¯‘ç”Ÿæˆ HTML ä»£ç ï¼Œå‘½ä»¤å¦‚ä¸‹ï¼šhexo generateå¯ä»¥çœ‹åˆ°è¾“å‡ºç»“æœé‡Œé¢åŒ…å«äº† jsã€cssã€font ç­‰å†…å®¹ï¼Œå¹¶å‘ç°ä»–ä»¬éƒ½å¤„åœ¨äº†é¡¹ç›®æ ¹ç›®å½•ä¸‹çš„ public æ–‡ä»¶å¤¹ä¸‹é¢äº†ã€‚\nç„¶åä½¿ç”¨ Hexo æä¾›çš„ server å‘½ä»¤æŠŠåšå®¢åœ¨æœ¬åœ°è¿è¡Œèµ·æ¥ï¼Œå‘½ä»¤å¦‚ä¸‹ï¼šhexo server è¿è¡Œä¹‹åå‘½ä»¤è¡Œè¾“å‡ºå¦‚ä¸‹ï¼š\nINFO  Start processingINFO  Hexois running at http://localhost:4000 . Press Ctrl+C to stop.\næœ¬åœ° 4000 ç«¯å£ä¸Šå°±å¯ä»¥æŸ¥çœ‹åšå®¢ç«™ç‚¹ï¼Œå¦‚å›¾æ‰€ç¤ºï¼š\n\nä¸»é¢˜é…ç½®ç™»å½•å®˜ç½‘Hexoå®˜ç½‘,ç„¶åç‚¹å‡»ä¸»é¢˜é¡µé¢Themeä¸»é¢˜ï¼Œé€‰æ‹©ä¸€ä¸ªå–œæ¬¢ä¸»é¢˜ï¼Œæˆ‘è¿™è¾¹é€‰æ‹©çš„ä¸»é¢˜æ˜¯keepä¸»é¢˜ã€‚æ‰§è¡Œå®‰è£…å‘½ä»¤ï¼Œä¼šå°†ä¸»é¢˜æ–‡ä»¶å®‰è£…åœ¨node_modulesæ–‡ä»¶å¤¹ä¸­ã€‚\nnpm install hexo-theme-keep --save\n\næ‰§è¡Œhexo serverå‘½ä»¤æ‰§è¡Œæœ¬åœ°æŸ¥çœ‹ã€‚\nå¯ä»¥çœ‹å‡ºæ­¤æ—¶æ•°æ®å·²ç»æ›´æ–°æˆkeepä¸»é¢˜ã€‚\néƒ¨ç½²åˆ°Githubæ‰§è¡Œéƒ¨ç½²åˆ°Githubéœ€è¦ä½¿ç”¨hexo-deployer-gitæ’ä»¶\nnpm install hexo-deployer-git --save\nå®‰è£…å¥½hexo-deployer-gitåå¯ä»¥è¿›è¡Œæ–‡ä»¶çš„é…ç½®ã€‚å…·ä½“é…ç½®å¦‚ä¸‹ï¼š\n\nåœ¨è¿™ä¹‹å‰éœ€è¦githubé…ç½®ç›¸åº”çš„ä»“åº“ï¼Œæˆ‘é…ç½®çš„ä»“åº“åä¸ºï¼šyqstar.github.io.\n\n\nå‚è€ƒMoreInfo:hexo-asset-imageæ’ä»¶MoreInfo:å¦‚ä½•ä½¿ç”¨æœ¬åœ°æ’å…¥å›¾ç‰‡\n"}]